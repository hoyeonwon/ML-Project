{"metadata":{"kernelspec":{"name":"ir","display_name":"R","language":"R"},"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"4.0.5"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction to Amazon Customer Reviews Project\n\n# 1. The project\nThe current competition aims to predict customer sentiments regarding [Baby products purchased on Amazon.com](http://jmcauley.ucsd.edu/data/amazon/), on the basis of their written reviews. Prior to starting with data analysis, we would like to first answer these three fundamental questions fo any ML project:\n\n**1. Where do the data come from? (To which population will results generalize?)**\n* The data originated from Emily Fox, Ph.D., Carlos Guestrin, Ph.D., and Julian McAuely on amazon product reviews on baby products from May 1996 to July 2014. As it can be seen, the data was collected from English speaking country (the USA), meaning we will be only able to generalize the reviews to the American websites that sell baby products.\n\n**2. What are candidate machine learning methods? (models? features?)**\n* As the problem issues binary outcomes, we can classify this problem as a binary classification problem. The  candidates are:\n<div style=\"display:flex; flex-direction: row; flex-wrap: nowrap; align-items: stretch; width:100%;\">\n    <div style=\"display:inline-block;width:45%;\">\n        <ul>\n<h5> Model Candidates: </h5>          \n<li> Ridge Regression\n<li> Lasso Regression\n<li> Partial Least Squares\n<li> Principal Component Regression\n<li> Smoothing\n<li> KNN\n        </ul>\n    </div>\n    <div style=\"display:inline-block;width:45%;\">\n        <ul>\n<h5> Feature Candidates: </h5>  \n<li> Sentiment Analysis using AFINN\n<li> Emotion Words from NRC\n<li> Lexical Diversity (amount of unique words)\n<li> Amount of Articles and Fillerwords\n<li> Average Word/ Sentence Length\n<li> Stopword Proportions\n<li> Ajective/ Linking/ Unique Words Proportions\n<li> Total Word Count\n<li> Average Number of Words per Sentence\n<li> Bigram Analysis/ n_grams\n<li> TF_IDF: relative importance of words\n<li> Word Correlations\n<li> Positive words related to reviews and ratings\n\nFor the final submission, we removed following features: word correlations and fillerword counts, as they make little sense as predictors for written and relatively short texts.\n        </ul>\n    </div>","metadata":{}},{"cell_type":"markdown","source":"**3. What is the Bayes' error bound?**\n* Human performance on this task can be assumed to be above chance. If it were about the concrete ratings (5 stars), accuracy would be lower, but for binary classification into satisfied and not satisfied, we can guess accuracy to be about 80%. Other literature on similar problems also suggest an accuracy of about 85% (Mtetwa, 2018; Deshpande, 2021).\n\n\n----------","metadata":{}},{"cell_type":"markdown","source":"# 2. Read Data\n\nThis step simply contains installing necessary packages and reading datasets","metadata":{"_uuid":"ea195a804433c840f3dab99683f4e8b9e69c55a0"}},{"cell_type":"code","source":"# Importing packages\nsuppressMessages(library(tidyverse))\nsuppressMessages(library(tidytext))\nsuppressMessages(library(caret))\nsuppressMessages(library(glmnet))\nsuppressMessages(library(pls))\nsuppressMessages(library(pROC))\n\n# Data attached to this notebook\nlist.files(path = \"../input\")","metadata":{"execution":{"iopub.status.busy":"2022-10-10T08:39:48.930269Z","iopub.execute_input":"2022-10-10T08:39:48.932021Z","iopub.status.idle":"2022-10-10T08:39:54.583675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dir(\"../input\", recursive=TRUE)","metadata":{"_uuid":"f66f7f950943394a8a4a148177f47055988d9967","execution":{"iopub.status.busy":"2022-10-10T08:39:54.585918Z","iopub.execute_input":"2022-10-10T08:39:54.61462Z","iopub.status.idle":"2022-10-10T08:39:54.654861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Find the right file path\ncsv_filepath = dir(\"..\", pattern=\"amazon_baby.csv\", recursive=TRUE, full.names = TRUE)\n\n# Read in the csv file\namazon = read_csv(csv_filepath) %>%\n    rownames_to_column('id') ","metadata":{"_uuid":"9ac5a75e758d075847213a02fe4ccff21c025b2a","execution":{"iopub.status.busy":"2022-10-10T08:39:57.789827Z","iopub.execute_input":"2022-10-10T08:39:57.792335Z","iopub.status.idle":"2022-10-10T08:40:01.055866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check how many train and test data are included:\ntrainidx = !is.na(amazon$rating)\ntable(trainidx)","metadata":{"_uuid":"929ae8a13ffecf79e218434ae79b1be6140ebcd7","execution":{"iopub.status.busy":"2022-10-10T08:40:02.482838Z","iopub.execute_input":"2022-10-10T08:40:02.485508Z","iopub.status.idle":"2022-10-10T08:40:03.087259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above, there are 153,531 training samples and 30,000 test samples.\n\n----------","metadata":{"_uuid":"548e07947ca115cc8138c438c8e6487acb62a6c0"}},{"cell_type":"markdown","source":"# 3. Preprocessing\n\nPrepend the product name to the review text: paste the `name` string and `review` string into a single string using the `unite()` function:","metadata":{}},{"cell_type":"code","source":"# Paste name and review into a single string separated by a \"–\".\n# The new string replaces the original review.\namazon = amazon %>% \n    unite(review, name, review, sep = \" — \", remove = FALSE) %>%\n     mutate(satisfied = ifelse(rating > 3, 1, 0))","metadata":{"execution":{"iopub.status.busy":"2022-10-10T08:40:06.122927Z","iopub.execute_input":"2022-10-10T08:40:06.124411Z","iopub.status.idle":"2022-10-10T08:40:07.462364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The data frame contains both the train and test data. The test data are the reviews for which the rating is missing and need to be provided with a prediction. ","metadata":{}},{"cell_type":"markdown","source":"## 3.1 Tokenization\n\nWe're going to use tidytext to break up the text into separate tokens and count the number of occurences per review. To keep track of the review to which the review belongs, we have added the rownames as `id` above, which is simply the row number. As tokens you can consider single words, pairs of words called bi-grams, or n-grams. ","metadata":{"_uuid":"6098328162f312fdc8dbc3928891e85dbf1e479a"}},{"cell_type":"code","source":"reviews = amazon %>% \n\n   # tokinize reviews at word level\n   unnest_tokens(token, review) %>%\n\n   # count tokens within reviews as 'n'\n   # (keep id, name, and rating in the result)\n   count(id, name, token, satisfied)\n\nhead(reviews)","metadata":{"_uuid":"fca425b0d51862febe3d304fe00b95b7d0cd0769","execution":{"iopub.status.busy":"2022-10-10T08:40:10.422333Z","iopub.execute_input":"2022-10-10T08:40:10.42386Z","iopub.status.idle":"2022-10-10T08:44:51.715549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n# 4. Features engineering\n\n## Features: Competition 1\n### Word Features\nHere we calculate the total number of words per review, as well as the average number of words per sentence in each review, as there might be differences in how much people write in their reviews depending on whether or not they rate the product highly. For example, some people might give a more in-depth explanation of what they did not like about the product, which in turn might also be related to how many words are used per sentence.","metadata":{"_uuid":"fdf9400f7df6154bc5376ce3c5a213f56dd0560d"}},{"cell_type":"code","source":"## Total Word Count\ntotal_count <- reviews %>% \n    group_by(id) %>%\n    summarize(word_count = n(), .groups = \"drop\") %>%\n    replace(is.na(.), 0)\n\n## Average number of words per sentence\nsentence_tokens <- amazon %>%\n    unnest_tokens(sentence, review, token = 'sentences') #tokenization into sentences\n\nn_words_in_sentence <- sentence_tokens %>%\n    mutate(sentence_indice = c(1:nrow(sentence_tokens))) %>% #adding indices to keep track of sentences\n    unnest_tokens(word, sentence, token = \"words\") %>% #break up sentences into words\n    mutate(tally = 1) %>% #add tallies for every word\n    group_by(id, sentence_indice) %>% \n    summarise(words_per_sentence = sum(tally), .groups = \"drop\") #get the words per sentence\n\nn_words_in_sentence <- n_words_in_sentence %>%\n    group_by(id) %>%\n    summarise(mean_words_sentence = mean(words_per_sentence)) %>%\n    replace(is.na(.), 0)","metadata":{"execution":{"iopub.status.busy":"2022-10-10T08:44:51.71789Z","iopub.execute_input":"2022-10-10T08:44:51.71919Z","iopub.status.idle":"2022-10-10T08:45:27.367292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We make the features into a format that is compatible with the design matrix later on:","metadata":{}},{"cell_type":"code","source":"total_count = total_count %>%\n    mutate(token = \"word_count\", .before = word_count) %>%\n    rename(\"value\" = word_count)\nn_words_in_sentence = n_words_in_sentence %>%\n    mutate(token = \"n_words_in_sentence\", .before = mean_words_sentence) %>%\n    rename(\"value\" = mean_words_sentence)","metadata":{"execution":{"iopub.status.busy":"2022-10-10T08:46:40.496643Z","iopub.execute_input":"2022-10-10T08:46:40.498236Z","iopub.status.idle":"2022-10-10T08:46:40.536932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Features: Sentiment Analysis using AFINN\n\nWe choose to do a sentiment analysis using the AFINN dictionary. Using this dictionary, each word gets a score assigned that ranges between -5 and 5. Negative words are scored < 0, whereas postive words are score > 0. We expect scores < 0 for the unsatisfying reviews and > 0 for positive reviews.","metadata":{}},{"cell_type":"code","source":"#import afinn dictionary\ndownload.file(\"http://www2.imm.dtu.dk/pubdb/edoc/imm6010.zip\",\"afinn.zip\")\nunzip(\"afinn.zip\")\nafinn = read.delim(\"AFINN/AFINN-111.txt\", sep=\"\\t\", col.names = c(\"word\",\"score\"), stringsAsFactors = FALSE)","metadata":{"execution":{"iopub.status.busy":"2022-10-10T08:46:44.341878Z","iopub.execute_input":"2022-10-10T08:46:44.343448Z","iopub.status.idle":"2022-10-10T08:46:45.378222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#map words from afinn dict. with words in the reviews\nsent <- reviews %>% \n    inner_join(afinn,by = c(\"token\" = \"word\")) ","metadata":{"execution":{"iopub.status.busy":"2022-10-10T08:46:46.261099Z","iopub.execute_input":"2022-10-10T08:46:46.262545Z","iopub.status.idle":"2022-10-10T08:46:47.417463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#count appearences of words in reviews\nsent = sent %>% #\n    group_by(id) %>%\n    mutate(product = n*score,\n          token = \"sent_score\") %>% \n    summarise(\"value\" = sum(product))","metadata":{"execution":{"iopub.status.busy":"2022-10-10T08:46:47.871385Z","iopub.execute_input":"2022-10-10T08:46:47.872935Z","iopub.status.idle":"2022-10-10T08:46:49.449118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Features: Lexical diversity\n\nLexical diversity can be defined by the amount of unique words in a passage of text. We expect positive reviews to be more well-written and thoughtful about the word choice. Therefore, the lexical diversity is believed to be higher for these reviews.","metadata":{}},{"cell_type":"code","source":"#we calculate the number of unique words for each review\nunique_words <- reviews %>%\n    group_by(id) %>%\n    summarise(lex_diversity = n_distinct(token)) ","metadata":{"execution":{"iopub.status.busy":"2022-10-10T08:46:52.255577Z","iopub.execute_input":"2022-10-10T08:46:52.257259Z","iopub.status.idle":"2022-10-10T08:46:59.868035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#rename col\nunique_words = unique_words %>%\n    mutate(token = \"lex_diversity\", .before = lex_diversity) %>%\n    rename(\"value\" = lex_diversity)","metadata":{"execution":{"iopub.status.busy":"2022-10-10T08:46:59.870432Z","iopub.execute_input":"2022-10-10T08:46:59.871777Z","iopub.status.idle":"2022-10-10T08:46:59.896904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Features: Emotion words from NRC\n\nWe included emotion words because the use of emotion is likely to be related to the review rating. Scores on negative emotions such as anger, sadness and disgust are likely to be higher in unsatisfied reviews than satisfied reviews","metadata":{}},{"cell_type":"code","source":"# Load emotion words\nload_nrc = function() {\n    if (!file.exists('nrc.txt'))\n        download.file(\"https://www.dropbox.com/s/yo5o476zk8j5ujg/NRC-Emotion-Lexicon-Wordlevel-v0.92.txt?dl=1\",\"nrc.txt\")\n        nrc = read.table(\"nrc.txt\", \n                         col.names = c('word','sentiment','applies'), \n                         stringsAsFactors = FALSE)\n        nrc %>% \n            filter(applies == 1) %>% \n                select(-applies)\n}\n\nnrc = load_nrc()","metadata":{"execution":{"iopub.status.busy":"2022-10-10T08:47:03.868385Z","iopub.execute_input":"2022-10-10T08:47:03.86994Z","iopub.status.idle":"2022-10-10T08:47:06.15676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tokenize dataset\nemotion <- reviews %>%\n    inner_join(nrc,by = c(\"token\" = \"word\"))\n\n# Create score for emotions\nsentiment_scores <- emotion %>%\n    count(`id`, sentiment) %>% # Create score for emotions\n    rename(\"token\" = sentiment, \"value\" = n)","metadata":{"execution":{"iopub.status.busy":"2022-10-10T08:47:06.613033Z","iopub.execute_input":"2022-10-10T08:47:06.614797Z","iopub.status.idle":"2022-10-10T08:47:29.097313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Features: Use of Articles\n\nUse of articles, like the, a, an, may indicate how descriptive the person is, and impact on how extreme the rating would be.","metadata":{}},{"cell_type":"code","source":"# Create a word count\nword_count <- reviews %>%\n    count(id) %>%\n    rename(word_count = n)","metadata":{"execution":{"iopub.status.busy":"2022-10-10T08:47:29.100372Z","iopub.execute_input":"2022-10-10T08:47:29.101709Z","iopub.status.idle":"2022-10-10T08:47:32.52306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate the amount of articles each person uses\narticles <- reviews %>%\n    filter(token == \"the\" | token == \"a\" | token == \"an\") %>%\n    count(id) %>%\n    rename(articles_count = n)","metadata":{"execution":{"iopub.status.busy":"2022-10-10T08:47:32.525428Z","iopub.execute_input":"2022-10-10T08:47:32.526734Z","iopub.status.idle":"2022-10-10T08:47:35.7412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate the amount of articles per word\ncount_words <- word_count %>% \n    full_join(articles, by = \"id\") %>%\n    mutate(articles_score = articles_count / word_count) %>%\n    replace(is.na(.), 0) %>%\n    select(id, articles_score) %>%\n    mutate(token = \"articles_score\", .before = articles_score) %>%\n    rename(\"value\" = articles_score)","metadata":{"execution":{"iopub.status.busy":"2022-10-10T08:47:35.744248Z","iopub.execute_input":"2022-10-10T08:47:35.745575Z","iopub.status.idle":"2022-10-10T08:47:35.868745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Features: Average Word/ Sentence Length\nWe calculated the average word and average sentence length in each review. These features can be useful as individuals with stronger opinions tend to write longer sentences, as well as longer words. The expression of the product may be more elaborate and thus indicate extremely higher (5) or lower (1) rating of the reviews. \n\nAverage word length was measured by the average amount of characters used per tokens, and average sentence length was measured from the average amount of tokens used in each sentence.","metadata":{}},{"cell_type":"code","source":"## Average word length \nword_length <- reviews %>% \n    group_by(id, satisfied) %>% \n    summarise(avg_word_len = nchar(token) %>%\n              mean(), .groups = \"drop\") %>%\n    select(id, avg_word_len) %>%\n    mutate(token = \"avg_word_len\", .before = avg_word_len) %>%\n    rename(\"value\" = avg_word_len)\n\n## Average sentence length\nsentence_length <- amazon %>%\n    unnest_tokens(sentences, review, token = \"sentences\") %>%\n    mutate(sentence_num = row_number()) %>%\n    unnest_tokens(words, sentences, token = \"words\") %>% \n    group_by(id, satisfied) %>%\n    count(sentence_num) %>%\n    summarise(avg_sen_len = mean(n), .groups = \"drop\") %>%\n    select(id, avg_sen_len) %>%\n    mutate(token = \"avg_sen_len\", .before = avg_sen_len) %>%\n    rename(\"value\" = avg_sen_len)","metadata":{"execution":{"iopub.status.busy":"2022-10-10T08:47:35.870988Z","iopub.execute_input":"2022-10-10T08:47:35.872309Z","iopub.status.idle":"2022-10-10T08:48:22.800446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Features: Proportions of the words\n\nWe calculated the proportions of unique sets of words from reviews dataset. The counting of each word seemed like a good indicator, but it may not be able to fully deliver the information because the proportions of the word count may be differ. Thus, we decided to use proportions of stopword, adjectives, linking words, and unique words as features. \n* Stopword is usually meaningless and insignificant that most of the people tend to ignore or remove from data analysis. However, we wanted to use the proportions of the stopword because it may contain some important information that we may easily not recognize. The elaboration of words (so the less stopword) may mean individuals are more eager to express their opinions and thus give either very high or low rating.\n* Adjectives also convey information because they also add elaboration into the words, showing how descriptive the review is.\n* Unique words may or may not give information about the ratings on reviews because it may show what kind of person is writing a review on, but not what kind of rating the review would get. However, it is still added as it showed some changes in sentiment analysis.","metadata":{}},{"cell_type":"code","source":"# Stopword Proportions\nsw_count = reviews %>% \n    # Add the total number of tokens per review as 'N'\n    add_count(id, name = \"N\") %>% \n\n    # Retain only tokens that are stopwords\n    inner_join(get_stopwords(), by = c(token='word')) %>% \n\n    # Compute the total number of stopwords per review\n    group_by(id, satisfied, N) %>% \n    summarise(n_stopwords = sum(n), .groups = \"drop\") %>%\n    mutate(sw_prop = n_stopwords/N) %>%\n    select(id, sw_prop) %>%\n    mutate(token = \"sw_prop\", .before = sw_prop) %>%\n    rename(\"value\" = sw_prop)\n\n# adjective list [List was acquired from this github repo: https://gist.github.com/hugsy/8910dc78d208e40de42deb29e62df913]\nadjective_list <- read.delim(url(\"https://gist.github.com/hugsy/8910dc78d208e40de42deb29e62df913/raw/eec99c5597a73f6a9240cab26965a8609fa0f6ea/english-adjectives.txt\"),\n                             header = FALSE)\nnames(adjective_list) <- paste(\"word\")\n\nadj_count = reviews %>% \n    add_count(id, name = \"N\") %>% \n    semi_join(adjective_list, by = c(token = \"word\")) %>%\n    group_by(id, satisfied, N) %>% \n    summarise(n_adjectives = sum(n), .groups = \"drop\") %>%\n    mutate(adj_prop = n_adjectives/N) %>%\n    select(id, adj_prop) %>%\n    mutate(token = \"adj_prop\", .before = adj_prop) %>%\n    rename(\"value\" = adj_prop)\n\n# Unique word Proportions\nunique_word_prop <- reviews %>%\n    add_count(id, name = \"N\") %>% \n    anti_join(get_stopwords(), by = c(token='word')) %>% \n     group_by(id, satisfied, N) %>% \n    summarise(unique_count = length(unique(token)), .groups = \"drop\") %>%\n    mutate(unique_prop = unique_count/ N) %>%\n    select(id, unique_prop) %>%\n    mutate(token = \"unique_prop\", .before = unique_prop) %>%\n    rename(\"value\" = unique_prop)","metadata":{"execution":{"iopub.status.busy":"2022-10-10T08:48:22.803061Z","iopub.execute_input":"2022-10-10T08:48:22.804452Z","iopub.status.idle":"2022-10-10T08:48:44.885092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Other Features\n\n### Features: Positive Words\n\nWe also found a list of positive words usually used in reviews (Songpan, 2017) and thought it was interesting to add as a predictor.\nThe positive words indicated higher ratings in reviews; thus we thought it would increase the accuracy, as it reflects the reality of reviews properly.","metadata":{}},{"cell_type":"code","source":"#search for positive words in the reviews\nposwords <- reviews %>%\n    filter(token == \"convenient\"|\n           token == \"good\" |\n           token == \"near\" |\n           token == \"comfortable\"|\n           token == \"very good \"|\n           token == \"cheap\"|\n           token == \"worth\"|\n           token == \"safe\"|\n           token == \"smile\"|\n           token == \"delicious\"|\n           token == \"beautiful\"|\n           token == \"luxurious\") %>%\n    count(id) %>%\n    rename(\"pos_count\" = n)\n\n# Create word count by dividing positive words by total words\ncount_pos <- word_count %>% \n    full_join(poswords, by = \"id\") %>%\n    mutate(pos_score= pos_count/word_count) %>%\n    replace(is.na(.), 0) %>%\n    select(id, pos_score) %>%\n    mutate(token = \"pos_score\", .before = pos_score) %>%\n    rename(\"value\" = pos_score)","metadata":{"execution":{"iopub.status.busy":"2022-10-10T08:48:44.887563Z","iopub.execute_input":"2022-10-10T08:48:44.888946Z","iopub.status.idle":"2022-10-10T08:48:48.952457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Features: Bigrams\nBigrams are used to tokenize consecutive sequences of words (showing how often word X is followed by word Y). We can see if there are relationships between different words. Bigrams, as they inlcude words like \"not\" and \"never\", we can use this to see if the rating can be predicted accurately.","metadata":{}},{"cell_type":"code","source":"# bigrams\nbigrams = amazon %>% \n  unnest_tokens(bigram, review, \"ngrams\", n = 2) %>% \n  count(id, name, rating, bigram)\n\n# Bigram tf_idf\ntf_idf_bigrams = bigrams %>%\n   bind_tf_idf(bigram, id, n) %>%\n    # remove near zero variance\n   filter(idf <= -log(0.5/100)) %>%\n    # replacing words that are not present are NA's with 0\n   replace_na(list(tf=0, idf=Inf, tf_idf=0)) %>%\n   rename(token = bigram) %>%\n   select(id, token, rating, tf_idf)\n\nhead(tf_idf_bigrams, 6)\n\n# remove bigrams considering limitations in memory\nrm(bigrams)\ngc()","metadata":{"execution":{"iopub.status.busy":"2022-10-10T08:49:33.791891Z","iopub.execute_input":"2022-10-10T08:49:33.793516Z","iopub.status.idle":"2022-10-10T08:56:53.669008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Select only the tf-idaf values, since that is what we are interested in and make it into a format that can be merged with all other features:","metadata":{}},{"cell_type":"code","source":"tf_idf_bigrams2 <- tf_idf_bigrams %>% \n    select(id, token, tf_idf) %>%\n    mutate(token = token, .before = tf_idf) %>%\n    rename(\"value\" = tf_idf)\n\ntf_idf_bigrams2$token <- paste(tf_idf_bigrams2$token, \"bigrams\", sep = \"_\") ","metadata":{"execution":{"iopub.status.busy":"2022-10-10T08:57:08.117465Z","iopub.execute_input":"2022-10-10T08:57:08.118867Z","iopub.status.idle":"2022-10-10T08:57:09.544557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Non-zero variance features\n\nFeatures that have almost no variance across cases cannot provide a lot of information about the target variable. Variance across cases is the leading principle in any data context. For binary and count data as considered here the variance is determined by the average (that's a mathetmatical fact). Hence, for the current data we can look simply at document frequencies and do not need to compute variances. \n\nWe will remove tokens that occur in less than 0.01% of the documents (there are ~180,000 reviews in the data set; less than 0.01% &times; 180,000 reviews = 18 of the reviews). The number 0.01% is quite arbitrary, but will remove idiosyncratic strings and miss-spellings that occur only in singular reviews. \n\nSince $IDF_t$, the column `idf`, which measures the surprise of a `token` $t$, is computed as \n\n$$IDF_t = -\\log\\left({\\text{df}_t \\over N}\\right) = -\\log(\\text{proportion of document in which }t\\text{ occurs})$$ \n\nwe can filter the rows in `features` for which $-\\log(\\text{df}_t / N) \\leq -\\log(0.01\\%)$ (i.e., the 'surprise' should be lower than $-\\log(0.01/100)$).\n\n\n**We removed non-zero variance features in one of the code chunks above when computing the tf-idf values.**\n\n","metadata":{"_uuid":"b79ad69b3b2b29c4e87abec0f3f3dd8ba0023e89"}},{"cell_type":"markdown","source":"### Features: TF-IDF\n\nTF-IDF, also total-frequency-inverse-document-frequency, is computed based on the total frequency of a word and the frequency of that word within a specific document. It is based on the reasoning that important and characteristic words of a specific document will occur more within that document compared to all others.\n\nThe code for the tf_idf computation is based on the literature as well as the kaggle notebook \"Huge design matrices - Spooky author\". When computing the tf-idf values, we decided not to remove stopwords since they turned out to be highly significant predictors of rating before.\nFirst, we compute the tf-idf values for all words across all \"documents\" (reviews). This design matrix can be used to fit a lasso regression later on.\nFor now, we have decided to keep the tf-idf separate from all other features since the dataframe is too big to merge, and the sparse matrix is not compatible for merging with the other features.","metadata":{}},{"cell_type":"code","source":"tf_idf_df = reviews %>% \n    # Compute TF·IDF for each word per sentence\n    count(name, id, token) %>% \n    bind_tf_idf(token, id, n) %>% \n\n    # Words that are not present in a particular scentence are NA's but should be 0\n    replace_na(list(tf=0, idf=Inf, tf_idf=0))\n\n#looking at the results\ntf_idf_df = tf_idf_df %>%\n    group_by(name) %>%\n    arrange(desc(tf_idf)) %>%\n    # Filtering for non-zero variance predictors\n    filter(idf <= -log(0.01/100)) %>%\n    ungroup()","metadata":{"execution":{"iopub.status.busy":"2022-10-10T08:57:15.774844Z","iopub.execute_input":"2022-10-10T08:57:15.776421Z","iopub.status.idle":"2022-10-10T09:03:15.8043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We select only the tf-idaf values, since that is what we are interested in and make it into a format that can be merged with all other features:","metadata":{}},{"cell_type":"code","source":"tf_idf_df1 <- tf_idf_df %>% \n    select(id, token, tf_idf) %>%\n    mutate(token = token, .before = tf_idf) %>%\n    rename(\"value\" = tf_idf)","metadata":{"execution":{"iopub.status.busy":"2022-10-10T09:03:15.806874Z","iopub.execute_input":"2022-10-10T09:03:15.808274Z","iopub.status.idle":"2022-10-10T09:03:15.835047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We add tf_idf to the end of all token words to differentiate between other features:","metadata":{}},{"cell_type":"code","source":"tf_idf_df1$token <- paste(tf_idf_df1$token, \"tf_idf\", sep = \"_\") ","metadata":{"execution":{"iopub.status.busy":"2022-10-10T09:03:15.837482Z","iopub.execute_input":"2022-10-10T09:03:15.838884Z","iopub.status.idle":"2022-10-10T09:03:19.530817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Merging all features into one dataframe\n\nFor the next step, we have merged all the features into one dataframe!\n","metadata":{}},{"cell_type":"code","source":"features_df = bind_rows(tf_idf_df1, tf_idf_bigrams2, total_count, n_words_in_sentence,\n                        sent, sentiment_scores, count_words,\n                        word_length, sentence_length, sw_count, adj_count,\n                        unique_word_prop, count_pos)","metadata":{"execution":{"iopub.status.busy":"2022-10-10T09:03:42.439189Z","iopub.execute_input":"2022-10-10T09:03:42.440731Z","iopub.status.idle":"2022-10-10T09:03:43.391563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As the features took a lot of memory in computational process, we removed the memories of each feature. ","metadata":{}},{"cell_type":"code","source":"rm(tf_idf_df, tf_idf_df1, tf_idf_bigrams2)","metadata":{"execution":{"iopub.status.busy":"2022-10-10T09:04:23.263579Z","iopub.execute_input":"2022-10-10T09:04:23.265153Z","iopub.status.idle":"2022-10-10T09:04:23.277602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n# 5. Models\n\n## Not relying on manual feature selection\n\nIn the Personality competition we computed features by utilizing word lists that in previous research were found to be predictive of sentiment. This requires substantial input from experts on the subject. If such knowledge is not (yet) available a process of trial and error can be used. But with many thousands of features automation of this process is essential. \n\n\nIn addition forward and/or backward selection, automated methods that try to automatically ballance flexibility and predictive performance are\n\n1. Lasso and Ridge regression\n2. Principal Components and Partial Least Squares regression\n3. Smoothing \n4. Regression and Classification trees (CART)\n5. Random Forests\n6. Support Vector Machines\n\nMethods (1) and (2) on this list involve methods are able to take many features while automatically reducing redundant flexibility to any desired level. Multicollinearity, the epithome of reduancy, is also automatically taken care of by these methods.\n\nNumber (3) on the list, smoothing, grants more flexibility by allowing for some non-linearity in the relations between features and the target variable, without the need to manually specify a specific mathematical form (as is necessary in polynomial regression).\n\nMethods (4), (5), and (6) are not only able to remove redundant features, but also can automatically recognize interactions between  features.\n\nHence, all of these methods remove the necessity of finding the best features by hand. \n\nAll of these methods are associated with a small set of 1 to 3 (or 4 in some cases) parameters that control the flexibility of the model in a more or less continuous way&mdash;much like the $k$ parameter in k-nearest neighbers. Like the $k$ parameter in k-NN, these parameters can and need to be adjusted (*'tuned'*) for optimal predictive performance. Tuning is best done on a validation set (a subset from the training data), or using cross-validation, depending on the size of the data set.","metadata":{"_uuid":"5b5c79f14ac762022e5755d91264cbae0730b58b","trusted":true}},{"cell_type":"markdown","source":"## 5.1 Model fitting\n\nNot all algorithms can deal with sparse matrices. For instance `lm()` can't. The package `glmnet`, which is extensively discussed in chapter 6 of ISLR, has a function with the same name `glmnet()` which can handle sparse matrices, and also allow you to reduce the model's flexibility by means of the Lasso penalty or ridge regression penalty. Furthermore, like the standard `glm()` function, it can also handle a variety of dependent variable families, including gaussian (for linear regression), binomial (for logistic regression), multinomial (for multinomial logistic regression), Poisson (for contingency tables and counts), and a few others. It is also quite caple of dealing computationally efficiently with the many features we have here.\n\n> <span style=color:brown>The aim of this competition is the predict the probability that a customer is ***satisfied***. This is deemed to be the case if `rating > 3`.  Hence, you will need as a dependent variable `y` a factor that specifies whether this is the case. </span>\n\nThe performance of your submission will be evaluated using the area under the curve (AUC) of the receiver operating curve (ROC). See chapter 4 in the ISLR book. See also the help file for how `cv.glmnet` can works with this measure.\n\nAs said, `glmnet()` allows you to tune the flexibility of the model by means of _regularizing_ the regression coefficients. The type of regularization (i.e., the Lasso or ridge) that is used is controled by the `alpha` parameter. Refer to the book for an explanation. The amount of regularization is specified by means of the `lambda` parameter. Read the warning in the `help(glmnet)` documentation about changing this parameter. To tune this parameter look at the `cv.glmnet()` function.\n","metadata":{"_uuid":"31b0ac2cecf396ee96aaab8cf8af9e022ebe2ef2"}},{"cell_type":"markdown","source":"Here we turn the dataframe containing our features into a sparse data matrix.","metadata":{}},{"cell_type":"code","source":"#into sparse matrix for lasso regression later\nsparse_matrix = features_df %>% \n    cast_sparse(row = id, column = token, value = value) %>% \n    # Remove rows that do not belong to cases\n    .[!is.na(rownames(.)),]\n\nsparse_matrix[1:8,20:25]\ncat(\"rows, columns: \", dim(sparse_matrix))","metadata":{"execution":{"iopub.status.busy":"2022-10-10T09:04:30.0151Z","iopub.execute_input":"2022-10-10T09:04:30.016631Z","iopub.status.idle":"2022-10-10T09:04:40.893859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We remove features_df and tf_idf to save memory space","metadata":{}},{"cell_type":"code","source":"rm(features_df)","metadata":{"execution":{"iopub.status.busy":"2022-10-10T09:05:07.703457Z","iopub.execute_input":"2022-10-10T09:05:07.705253Z","iopub.status.idle":"2022-10-10T09:05:07.719164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Then we split the data into test and training data.\nFor now, we only use a sample of 5000 for training the model as the full training data took too long to load.","metadata":{}},{"cell_type":"code","source":"train_ids = amazon %>%\n    filter(!is.na(satisfied)) %>%\n    select(id) %>%\n    pull()\n\ntest_ids = amazon %>%\n    select(id) %>%\n    filter(!id %in% train_ids) %>%\n    pull()","metadata":{"execution":{"iopub.status.busy":"2022-10-10T09:05:11.175467Z","iopub.execute_input":"2022-10-10T09:05:11.177149Z","iopub.status.idle":"2022-10-10T09:05:11.237503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Lasso Regression\nLasso is a alternative to ridge regression that overcomes the disadvantage of including all p predictors in the final model. Lasso minimizes the quantity by using lasso penalty. This helps performing variable selection and make it easier to interpret.\n\nFirst, we create a training data set and then a vector holding all outcome descriptions for that training data:","metadata":{}},{"cell_type":"code","source":"training_data <- sparse_matrix[rownames(sparse_matrix) %in% train_ids, ] ","metadata":{"execution":{"iopub.status.busy":"2022-10-10T09:05:17.829627Z","iopub.execute_input":"2022-10-10T09:05:17.831083Z","iopub.status.idle":"2022-10-10T09:05:18.506712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y =\n    data.frame(id=rownames(training_data)) %>% \n    inner_join(amazon, by = \"id\") %>% \n\n    # Extract 'satified' as a factor\n    pull(satisfied) %>%\n    as.factor()","metadata":{"execution":{"iopub.status.busy":"2022-10-10T09:05:19.992628Z","iopub.execute_input":"2022-10-10T09:05:19.994324Z","iopub.status.idle":"2022-10-10T09:05:20.216887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Then, we fit the model:","metadata":{}},{"cell_type":"code","source":"doMC::registerDoMC(cores = 4) \n\nfit_lasso <- glmnet::cv.glmnet(training_data, y, alpha = 1, family = \"binomial\", \n                               standardize = TRUE,\n                               parallel = TRUE,\n                            type.measure = \"auc\")","metadata":{"execution":{"iopub.status.busy":"2022-10-10T09:05:22.839296Z","iopub.execute_input":"2022-10-10T09:05:22.840912Z","iopub.status.idle":"2022-10-10T09:19:26.449351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we plot the AUC of the model as a function of the log of lambda:","metadata":{}},{"cell_type":"code","source":"fit_lasso\nplot(fit_lasso)","metadata":{"execution":{"iopub.status.busy":"2022-10-10T09:19:26.451877Z","iopub.execute_input":"2022-10-10T09:19:26.453785Z","iopub.status.idle":"2022-10-10T09:19:26.775697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Ridge Regression\nRidge regression can be used when there is a high number of predictors which exceeds the number of observations or can be used when there is multicollinearity between predictors.","metadata":{}},{"cell_type":"code","source":"fit_ridge <- glmnet::cv.glmnet(training_data, y, alpha = 0, family = \"binomial\", \n                               standardize = TRUE,\n                               parallel = TRUE,\n                            type.measure = \"auc\")","metadata":{"execution":{"iopub.status.busy":"2022-10-10T09:19:26.779432Z","iopub.execute_input":"2022-10-10T09:19:26.781423Z","iopub.status.idle":"2022-10-10T09:29:56.118052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we plot the AUC of the model as a function of the log of lambda:","metadata":{}},{"cell_type":"code","source":"fit_ridge\nplot(fit_ridge)","metadata":{"execution":{"iopub.status.busy":"2022-10-10T09:29:56.120541Z","iopub.execute_input":"2022-10-10T09:29:56.121961Z","iopub.status.idle":"2022-10-10T09:29:56.240903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Other Models:\nOther candidate models that we tried to fit to the data were: K-Nearest-Neighbours, Naive Bayes, Principal Component Regression. Unforutnately these models do not work well with a sparse matrix, thus we fit them on the remaining predictors. As the tf-idf features make up majority of the predictors, we did not expect these models to perform well due to loss of information.\n\nWe then create a dataframe containing reviewer ids in the rows and all remaining predictors in the columns:","metadata":{}},{"cell_type":"code","source":"total_count2 <- total_count %>% #\n    select(id, value) %>%\n    rename(\"word_count\" = value) \nn_words_in_sentence2 <- n_words_in_sentence %>%\n    select(id, value) %>%\n    rename(\"n_words_in_sentence\" = value)\nsent2 <- sent %>%\n    select(id, value) %>%\n    rename(\"sent\" = value) %>%\n    right_join(amazon, by = \"id\", values_fill = 0) %>%\n    select(id, sent)\nsentiment_scores2 <- emotion %>%\n    count(`id`, sentiment) %>%\n    pivot_wider(names_from = sentiment, values_from = n) %>%\n    right_join(amazon, by = \"id\", values_fill = 0) %>%\n    select(id, c(unique(emotion$sentiment)))\ncount_words2 <- count_words %>%\n    select(id, value) %>%\n    rename(\"count_words\" = value) %>%\n    right_join(amazon, by = \"id\", values_fill = 0) %>%\n    select(id, count_words)\nword_length2 <- word_length %>%\n    select(id, value) %>%\n    rename(\"word_length\" = value) %>%\n    right_join(amazon, by = \"id\", values_fill = 0) %>%\n    select(id, word_length)\nsentence_length2 <- sentence_length %>%\n    select(id, value) %>%\n    rename(\"sentence_length\" = value) %>%\n    right_join(amazon, by = \"id\", values_fill = 0) %>%\n    select(id, sentence_length)\nsw_count2 <- sw_count %>%\n    select(id, value) %>%\n    rename(\"sw_count\" = value) %>%\n    right_join(amazon, by = \"id\", values_fill = 0) %>%\n    select(id, sw_count)\nadj_count2 <- adj_count %>%\n    select(id, value) %>%\n    rename(\"adj_count\" = value) %>%\n    right_join(amazon, by = \"id\", values_fill = 0) %>%\n    select(id, adj_count)\nunique_word_prop2 <- unique_word_prop %>%\n    select(id, value) %>%\n    rename(\"unique_word_prop\" = value) %>%\n    right_join(amazon, by = \"id\", values_fill = 0) %>%\n    select(id, unique_word_prop)\ncount_pos2 <- count_pos %>%\n    select(id, value) %>%\n    rename(\"count_pos\" = value) %>%\n    right_join(amazon, by = \"id\", values_fill = 0) %>%\n    select(id, count_pos)","metadata":{"execution":{"iopub.status.busy":"2022-10-10T09:30:06.959203Z","iopub.execute_input":"2022-10-10T09:30:06.960801Z","iopub.status.idle":"2022-10-10T09:30:31.686472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We bring it together into a new dataframe:","metadata":{}},{"cell_type":"code","source":"features_df2 <- total_count2 %>%\n    left_join(n_words_in_sentence2, by = \"id\") %>%\n    left_join(sent2, by = \"id\") %>%\n    left_join(sentiment_scores2, by = \"id\") %>%\n    left_join(count_words2, by = \"id\") %>%\n    left_join(word_length2, by = \"id\") %>%\n    left_join(sentence_length2, by = \"id\") %>%\n    left_join(sw_count2, by = \"id\") %>%\n    left_join(adj_count2, by = \"id\") %>%\n    left_join(unique_word_prop2, by = \"id\") %>%\n    left_join(count_pos2, by = \"id\") #","metadata":{"execution":{"iopub.status.busy":"2022-10-10T09:31:44.257118Z","iopub.execute_input":"2022-10-10T09:31:44.258785Z","iopub.status.idle":"2022-10-10T09:31:44.886922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We replace NA values by 0 and add the outcome variable to the dataframe and remove the test data:","metadata":{}},{"cell_type":"code","source":"features_df2 <- features_df2 %>%\n    replace(is.na(.), 0)\nfeatures_df2 <- amazon %>%\n    select(id, satisfied) %>%\n    left_join(features_df2, by = \"id\") %>%\n    filter(id %in% train_ids) %>%\n    select(-id)","metadata":{"execution":{"iopub.status.busy":"2022-10-10T09:31:47.632639Z","iopub.execute_input":"2022-10-10T09:31:47.634167Z","iopub.status.idle":"2022-10-10T09:31:48.025227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Remove features that are superfluous:","metadata":{}},{"cell_type":"code","source":"rm(total_count, n_words_in_sentence, sent, sentiment_scores, count_words,\n   word_length, sentence_length, sw_count, adj_count, unique_word_prop, count_pos,\n   total_count2, n_words_in_sentence2, sent2, sentiment_scores2, count_words2,\n   word_length2, sentence_length2, sw_count2, adj_count2, unique_word_prop2, count_pos2)","metadata":{"execution":{"iopub.status.busy":"2022-10-10T09:31:51.417814Z","iopub.execute_input":"2022-10-10T09:31:51.420643Z","iopub.status.idle":"2022-10-10T09:31:51.434785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Then we fit the models:\n\n### KNN\nK-nearest neighbors (KNN) is a non-parametric approach, meaning it does not assume anything of the decision boundary. One of the advantages of non-parametric model is that it can display better output when the decision boundary is non-linear.","metadata":{}},{"cell_type":"code","source":"## KNN\nset.seed(1)\ntrcntr = caret::trainControl('cv', number = 10) \n\nfit_knn <- caret::train(factor(satisfied) ~ ., data = features_df2, method=\"knn\", trControl = trcntr, preProcess = 'scale')\nfit_knn\n\n# the plot shows the ideal k-fold\n# plot(fit_knn)","metadata":{"execution":{"iopub.status.busy":"2022-10-10T09:32:05.903844Z","iopub.execute_input":"2022-10-10T09:32:05.905374Z","iopub.status.idle":"2022-10-10T10:06:10.848189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Partial Least Squares Regression\n\nPartial Least Squares Regression can be used for dimension reduction.\nHere we fit the model with ten-fold crossvalidation, as well as using standardized values.","metadata":{}},{"cell_type":"code","source":"set.seed(1)\nfit_pls <- plsr(satisfied ~ ., data = features_df2,\n                scale = TRUE, validation = \"CV\")","metadata":{"execution":{"iopub.status.busy":"2022-10-10T10:07:06.127474Z","iopub.execute_input":"2022-10-10T10:07:06.129825Z","iopub.status.idle":"2022-10-10T10:07:22.861187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validationplot(fit_pls, val.type = \"MSEP\")","metadata":{"execution":{"iopub.status.busy":"2022-10-10T10:07:26.409496Z","iopub.execute_input":"2022-10-10T10:07:26.411059Z","iopub.status.idle":"2022-10-10T10:07:26.602694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Principal Component Regression\nPCR is a regression technique that can be used to analyze multiple regression data suffering from multicollinearity. Instead of original features, principal components are used as predictors. PCR needs to be fit on a datamatrix.","metadata":{}},{"cell_type":"code","source":"set.seed(1)\npcr_fit <- pcr(satisfied ~ . , data = features_df2,\n               scale = TRUE, validation = \"CV\")","metadata":{"execution":{"iopub.status.busy":"2022-10-10T10:07:30.416946Z","iopub.execute_input":"2022-10-10T10:07:30.418414Z","iopub.status.idle":"2022-10-10T10:07:44.635158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validationplot(pcr_fit, val.type = \"MSEP\")","metadata":{"execution":{"iopub.status.busy":"2022-10-09T22:56:21.830011Z","iopub.execute_input":"2022-10-09T22:56:21.83163Z","iopub.status.idle":"2022-10-09T22:56:21.95732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.2 Model evaluation\n\n","metadata":{}},{"cell_type":"markdown","source":"Given that AUC is the performance measure used to rate the submission in this competition,we compare the models by this measure.","metadata":{}},{"cell_type":"markdown","source":"First, we compute the Accuracy and AUC of all models:","metadata":{}},{"cell_type":"code","source":"#Lasso Regression:\n\n# Performance on test set\npred_lasso = predict(fit_lasso, training_data, s='lambda.min', type='class') %>% factor()\ncaret::confusionMatrix(pred_lasso, y)\n\n# evaluation statistics\nLasso <- c(mean(pred_lasso == y), max(fit_lasso$cvm))\n\n#Ridge Regression:\n\n# Performance on test set\npred_ridge = predict(fit_ridge, training_data, s='lambda.min', type='class') %>% factor()\ncaret::confusionMatrix(pred_ridge, y)\n\n#evaluation statistics\nRidge <- c(mean(pred_ridge == y), max(fit_ridge$cvm)) ","metadata":{"execution":{"iopub.status.busy":"2022-10-10T10:08:45.21588Z","iopub.execute_input":"2022-10-10T10:08:45.217419Z","iopub.status.idle":"2022-10-10T10:08:46.226478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For PCR and PLS the number of components chosen for making the predictions was based on the validationplots.","metadata":{}},{"cell_type":"code","source":"#PCR:\npcr_pred <- predict(pcr_fit, ncomp = 15, type = \"resp\") \npcr_acc <- mean(ifelse(pcr_pred < 0.5, 0, 1) == y)\n\npcr_auc <- auc(y, ifelse(pcr_pred < 0.5, 0, 1))\n\nPCR <- c(pcr_acc, pcr_auc)\n\n#PLS\npls_pred <- predict(fit_pls, ncomp = 4, type = \"resp\")\npls_acc <- mean(ifelse(pls_pred < 0.5, 0, 1) == y)\n\npls_auc <- auc(y, ifelse(pls_pred < 0.5, 0, 1))\n\nPLS <- c(pls_acc, pls_auc)","metadata":{"execution":{"iopub.status.busy":"2022-10-10T10:22:22.085765Z","iopub.execute_input":"2022-10-10T10:22:22.08744Z","iopub.status.idle":"2022-10-10T10:22:22.870758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Predict fit_knn for auc and accuracy scores:","metadata":{}},{"cell_type":"code","source":"#KNN\n\nknn_pred <- predict(fit_knn)\nknn_acc <- mean(knn_pred == y)\nknn_auc <- pROC::roc(response = y, predictor = as.numeric(knn_pred))","metadata":{"execution":{"iopub.status.busy":"2022-10-10T10:24:18.546237Z","iopub.execute_input":"2022-10-10T10:24:18.54915Z","iopub.status.idle":"2022-10-10T10:33:05.161336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Finally merge acc and auc scores to KNN:","metadata":{}},{"cell_type":"code","source":"KNN <- c(knn_acc, knn_auc$auc)","metadata":{"execution":{"iopub.status.busy":"2022-10-10T10:47:26.85363Z","iopub.execute_input":"2022-10-10T10:47:26.855344Z","iopub.status.idle":"2022-10-10T10:47:26.86876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Then, we compare them visually:","metadata":{}},{"cell_type":"code","source":"perf_comp <- data.frame(Ridge = Ridge, Lasso = Lasso, KNN = KNN, PCR = PCR, PLS = PLS) \nrow.names(perf_comp) <- c(\"Accuracy\", \"AUC\")\n\nperf_comp\n\nAUC_model <- c(max(fit_ridge$cvm), max(fit_lasso$cvm), KNN[2], PCR[2], PLS[2])\n\nbarplot(AUC_model, \n        xlab=\"AUC\", \n        #horiz=TRUE,\n        names.arg=c(\"Ridge\", \"Lasso\", \"KNN\", \"PCR\", \"PLS\"),\n        col=c(\"Skyblue\",\"Pink\", \"Red\", \"Green\", \"Orange\"))","metadata":{"execution":{"iopub.status.busy":"2022-10-10T10:53:28.606292Z","iopub.execute_input":"2022-10-10T10:53:28.609278Z","iopub.status.idle":"2022-10-10T10:53:28.717339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## CONCLUSION\n\nBased on the plots we can conclude that `lasso` resulted in the best accuracy. However, `ridge` reached a quite similar accuracy, which was slightly less than `lasso`. This is expected as `lasso` method overcomes the disadvantage of `ridge` via giving penalty high values of the coefficient as well as setting the coefficients to zero if they do not have any relevance with the model. \nFor other three models, `KNN`, `PCR`, and `PLS`, they had much less accuracy than `ridge` or `lasso`. This was because when dealing with a high number of features, these models tend to have lower accuracy.","metadata":{}},{"cell_type":"markdown","source":"\n# 6. Submitting your predictions\n","metadata":{"_uuid":"db4164fa915f86b512ba3a4a576683dcf4b48320","trusted":true}},{"cell_type":"markdown","source":"We create a test data set & Then we compute the probabilities for this test data and make them into a tibble:\n\nLasso and Ridge regression performs similarly (though Lasso is slightly higher), but since Lasso imposes a higher penalty on coefficients (sparse solution), we go with Lasso for predictions.","metadata":{}},{"cell_type":"code","source":"test_data <- sparse_matrix[rownames(sparse_matrix) %in% test_ids, ]\n\ntest_preds <- predict(fit_lasso, \n               test_data, \n               s = \"lambda.min\", \n               type = \"response\")\n\nsubmission = tibble(Id = rownames(test_preds), \n                    Prediction = test_preds[,1]) %>%\n    arrange(as.integer(Id))\n\nhead(submission)","metadata":{"execution":{"iopub.status.busy":"2022-10-10T10:49:19.235368Z","iopub.execute_input":"2022-10-10T10:49:19.237037Z","iopub.status.idle":"2022-10-10T10:49:20.053354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Then we write the predictions into a csv file for submission:","metadata":{}},{"cell_type":"code","source":"write_csv(submission, file=\"submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-10-10T10:49:23.341663Z","iopub.execute_input":"2022-10-10T10:49:23.343224Z","iopub.status.idle":"2022-10-10T10:49:23.39481Z"},"trusted":true},"execution_count":null,"outputs":[]}]}