{"metadata":{"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"4.0.5"},"kernelspec":{"name":"ir","display_name":"R","language":"R"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"library(tidyverse) \nlibrary(tidytext)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this cell (by clicking ▶️, run or pressing Shift+Enter) will list \n# all files under the \"../input/\" directory\n\nlist.files(path = \"../input\")","metadata":{"_uuid":"047afe52-49c0-4445-bc38-8ce6b6825e9d","_cell_guid":"39fc8038-1e29-4bb3-8486-160aa629127b","_execution_state":"idle","execution":{"iopub.status.busy":"2022-09-19T07:59:22.090721Z","iopub.execute_input":"2022-09-19T07:59:22.132885Z","iopub.status.idle":"2022-09-19T07:59:22.159553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are three .csv files in the directory structure:","metadata":{"_uuid":"dcb2b11f-1f84-42ed-bcea-e423337c4200","_cell_guid":"e96f7417-8cec-4390-aa25-b7fb7b0d137f","trusted":true}},{"cell_type":"code","source":"directory_content = list.files(\"../input/bda-2022-personality-profiling/youtube-personality\", full.names = TRUE)\nprint(directory_content)","metadata":{"_uuid":"5a7e0e4d-bd75-4313-ad70-0df228feef48","_cell_guid":"60fffa58-51df-4b85-8405-7208ac965554","execution":{"iopub.status.busy":"2022-09-19T07:59:22.162586Z","iopub.execute_input":"2022-09-19T07:59:22.164367Z","iopub.status.idle":"2022-09-19T07:59:22.191703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In addition there's a \"transcript\" folder (see number \\[2\\] in the output above) in which the actual video transcripts are stored in `.txt` files. \n\nStore these file paths in variables for easy reference later on:","metadata":{"_uuid":"f4f5800e-e781-4c2b-a2da-8d42ea353a2d","_cell_guid":"f8049998-2ebe-4324-8f2d-48050b8d95bc","trusted":true}},{"cell_type":"code","source":"# Path to the transcripts directory with transcript .txt files\npath_to_transcripts = directory_content[2] \n\n# .csv filenames (see output above)\nAudioVisual_file    = directory_content[3]\nGender_file         = directory_content[4]\nPersonality_file    = directory_content[5]","metadata":{"_uuid":"a73254cd-f66d-4422-9d4c-2521f79b39fc","_cell_guid":"94e0f55e-2f9a-4849-9bde-34feb94dc4f4","execution":{"iopub.status.busy":"2022-09-19T07:59:22.194886Z","iopub.execute_input":"2022-09-19T07:59:22.196743Z","iopub.status.idle":"2022-09-19T07:59:22.220293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Import the data\n\nWe'll import\n\n- Transcripts\n- Personality scores\n- Gender\n- Audiovisuals\n\n## 1.1 Importing transcripts\n\nThe transcript text files are stored in the subfolder 'transcripts'. They can be listed with the following commands:","metadata":{"_uuid":"5564aff0-1b9a-4ad0-8deb-c59822efb02f","_cell_guid":"1e2591f6-6257-49b6-b8ca-5211d63b2c15","trusted":true}},{"cell_type":"code","source":"transcript_files = list.files(path_to_transcripts, full.names = TRUE) \n\nprint(head(transcript_files))","metadata":{"_uuid":"9bb0363f-c1e8-4e78-95e8-240628cd1c56","_cell_guid":"83284cd6-8b82-4e44-b327-a7bb30035ea1","execution":{"iopub.status.busy":"2022-09-19T07:59:22.223559Z","iopub.execute_input":"2022-09-19T07:59:22.225383Z","iopub.status.idle":"2022-09-19T07:59:22.272503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The transcript file names encode the vlogger ID that you will need for joining information from the different data frames. A clean way to extract the vlogger ID's from the names is by using the funcation `basename()` and removing the file extension \".txt\".","metadata":{"_uuid":"4e3cb8fd-83db-4698-a565-2115a202fe9b","_cell_guid":"c87a60dd-6c43-4ed6-a35f-45d4efc47db6","trusted":true}},{"cell_type":"code","source":"vlogId = basename(transcript_files)\nvlogId = str_replace(vlogId, pattern = \".txt$\", replacement = \"\")\nhead(vlogId)","metadata":{"_uuid":"9a179032-bde8-462a-b223-89a45b1338d9","_cell_guid":"93382a21-dd15-4747-94b4-203131cbe705","execution":{"iopub.status.busy":"2022-09-19T07:59:22.275655Z","iopub.execute_input":"2022-09-19T07:59:22.27756Z","iopub.status.idle":"2022-09-19T07:59:22.310787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To include features extracted from the transcript texts you will have to read the text from files and store them in a data frame. For this, you will need the full file paths as stored in `transcript_files`.\n\nHere are some tips to do that programmatically\n\n- use either a `for` loop, the `sapply()` function, or the `map_chr()` from the `tidyverse`\n- don't forget to also store `vlogId` extracted with the code above \n\nWe will use the `map_chr()` function here:","metadata":{"_uuid":"a48356cc-bb9c-4edd-9cca-0082f5dfcdaf","_cell_guid":"e5bd1c34-e28f-4b02-a1a5-c49037d8e40d","trusted":true}},{"cell_type":"code","source":"transcripts_df = tibble(\n    \n    # vlogId connects each transcripts to a vlogger\n    vlogId=vlogId,\n    \n    # Read the transcript text from all file and store as a string\n    Text = map_chr(transcript_files, ~ paste(readLines(.x), collapse = \"\\\\n\")), \n    \n    # `filename` keeps track of the specific video transcript\n    filename = transcript_files\n)","metadata":{"_uuid":"bb66ae39-9ef8-46fb-8971-082dc333bdb8","_cell_guid":"1553130b-5066-4d9b-8219-9c1ca9b3ba1a","execution":{"iopub.status.busy":"2022-09-19T07:59:22.31395Z","iopub.execute_input":"2022-09-19T07:59:22.315782Z","iopub.status.idle":"2022-09-19T07:59:23.800991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transcripts_df %>% \n    head(2)","metadata":{"_uuid":"71cac44a-ef63-4905-9301-3cac5bdb4853","_cell_guid":"6a33e296-2dbb-4aff-b538-a664c3b0c5ea","execution":{"iopub.status.busy":"2022-09-19T07:59:23.805787Z","iopub.execute_input":"2022-09-19T07:59:23.807868Z","iopub.status.idle":"2022-09-19T07:59:23.851626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import personality scores\n\nThe other data files can be read in with `read_delim` (not `read_csv` because the files are not actually comma separated). For instance, the following should work:","metadata":{"_uuid":"cbeff62e-1658-4d36-8343-e9a44a69b631","_cell_guid":"e6ae9665-5609-4491-a478-51e691e68549","trusted":true}},{"cell_type":"code","source":"# Import the Personality scores\npers_df = read_delim(Personality_file, delim=\" \")","metadata":{"_uuid":"a4f9c3b5-7277-4b3f-838e-e51d3acd321e","_cell_guid":"3b23f306-d346-457a-86e5-e567b85fc8c0","execution":{"iopub.status.busy":"2022-09-19T07:59:23.85658Z","iopub.execute_input":"2022-09-19T07:59:23.858978Z","iopub.status.idle":"2022-09-19T07:59:24.141022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"head(pers_df)","metadata":{"_uuid":"5d8dbb05-81b7-41eb-9ff5-b793c9da7a5f","_cell_guid":"610ba114-99e1-4b15-b451-1738110c3e93","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-19T07:59:24.143526Z","iopub.execute_input":"2022-09-19T07:59:24.144907Z","iopub.status.idle":"2022-09-19T07:59:24.171145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import gender\n\nGender info is stored in a separate `.csv` which is also delimited with a space. This file doesn't have column names, so we have to add them ourselves:","metadata":{"_uuid":"483309a5-f1d9-4c52-99f6-7981af701b15","_cell_guid":"0f1b8dec-eccb-4fe8-964d-f6ee2a2bfa2e","trusted":true}},{"cell_type":"code","source":"gender_df = read.delim(Gender_file, head=FALSE, sep=\" \", skip = 2)\n\n\n# Add column names\nnames(gender_df) = c('vlogId', 'gender')\n\n\nhead(gender_df)","metadata":{"_uuid":"42642c23-d42f-4265-afd8-e03477f0ec07","_cell_guid":"4addc5a4-5b6f-4fbe-a84f-7ee5733a8271","execution":{"iopub.status.busy":"2022-09-19T07:59:24.174075Z","iopub.execute_input":"2022-09-19T07:59:24.176147Z","iopub.status.idle":"2022-09-19T07:59:24.20814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Merging the `gender` and `pers` dataframes\n\nObviously, we want all the information in a single tidy data frame. While the builtin R function `merge()` can do that, the `tidyverse()` has a number of more versatile and consistent functions called `left_join`, `right_join`, `inner_join`, `outer_join`, and `anti_join`. We'll use `left_join` here to merge the gender and personality data frames:","metadata":{"_uuid":"4093194b-da93-4b07-996f-82c1fe810418","_cell_guid":"252e73f9-ed0f-4161-a6e8-f287e6dfaddc","trusted":true}},{"cell_type":"code","source":"vlogger_df = left_join(gender_df, pers_df, by='vlogId')\n\nhead(vlogger_df) # VLOG8 has missing personality scores: those should be predicted","metadata":{"_uuid":"58eb0582-3c68-458e-a807-187ef63fd52a","_cell_guid":"15d7bd85-f197-4803-8daa-6193f7929978","execution":{"iopub.status.busy":"2022-09-19T07:59:24.211303Z","iopub.execute_input":"2022-09-19T07:59:24.213313Z","iopub.status.idle":"2022-09-19T07:59:24.247753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Note that some rows, like row 5, has `NA`'s for the personality scores. This is because this row corresponds to the vlogger with vlogId `VLOG8` is part of the test set. You still have to split `vlogger_df` into the training and test set, as shown below.\n\nWe leave the `transcripts_df` data frame seperate for now, because you will first have to extract features from the transcripts first. Once you have those features in a tidy data frame, including a `vlogId` column, you can refer to this `left_join` example to merge your features with `vlogger_df` in one single tidy data frame.","metadata":{"_uuid":"d99b97d2-a621-4347-bde2-39e316bdf494","_cell_guid":"5ef44461-656c-4d24-8e4f-c137159fbc16","trusted":true}},{"cell_type":"markdown","source":"# 2. Feature extraction from transcript texts\n\nHere you will develop the code that extract features from the transcript texts using `tidytext`. Look at [Introducing Text Analytics](https://www.kaggle.com/datasniffer/introducing-text-analytics-personality-from-text) to see how you should do this.\n\n## Foreword:\nAlthough we provide clear reasoning for our feature selection, our group tried to use many reasonable features for our predictions. For the final feature selection we adhered to the statistical process rather than our intuition. This means we believed that it is more trustworthy and useful to use statistical selection (e.g. stepwise regression) to extract features from our collection, than simply selecting features based on our intuition. Thus, we tried to gather many features that ultimately provided more data, while performing a statistical selection.\n\nFirst, we initialized the required dataframes, tokenizing the text and preparing the final dataframe.","metadata":{"_uuid":"cda7cf6b-3680-4451-b1c5-6e276d2d5430","_cell_guid":"b3b16406-5f3b-45c5-b1a9-9d2f98d66210","trusted":true}},{"cell_type":"code","source":"# Here goes YOUR CODE to compute the dataframe `transcript_features_df`\n\n# Tokenization of vlog text \ntoken_df <- transcripts_df %>%\n    unnest_tokens(word, Text, token = \"words\") \n\n\n# Initialize 'transcript_features_df` dataframe as tibble to use tidy framework \ntranscript_features_df <- vlogger_df %>%\n    select(vlogId) %>%\n    tibble()\n\n\nhead(token_df)\nhead(transcript_features_df)","metadata":{"_uuid":"1540d512-f479-4475-aaa9-45c3acae5178","_cell_guid":"f80d89e3-c233-4a5d-ba0c-7f1ca9fb1b04","execution":{"iopub.status.busy":"2022-09-19T07:59:24.250767Z","iopub.execute_input":"2022-09-19T07:59:24.25264Z","iopub.status.idle":"2022-09-19T07:59:24.465163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature: Sentiment (NRC, AFINN, BING)\n\nWe used all the sentiment datasets, including AFINN, bing, and nrc. We especially extracted the emotions from nrc to have a more specific picture of conveyed emotions. These features include words assigned to positive / negative sentiment scores, as well as the use of emotions like anger, anticipation, disgust, fear, joy, sadness, surprise, and trust. The emotions / sentiment in a vlog may express attitudes and opinions of individuals. It gives us an opportunity to explore the quality or the characteristic of the vlogger, as they should reflect the way of thinking, perspectives, and emotions of the vlogger. Usually these characteristics all differ per different personality traits, so we would expect these features to benefit our prediction efforts. The first feature we created included a sentiment analysis of the text applying three distinct sentiment vocabularies.","metadata":{}},{"cell_type":"code","source":"# FEATURE: \"Sentiment\" \n# Sub-Feature: Bing\ntranscript_features_df <- token_df %>%\n    inner_join(get_sentiments(\"bing\"), by = \"word\") %>%\n    count(vlogId, sentiment) %>%\n    pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>%\n    mutate(sentiment_bing = positive - negative, .keep = \"unused\") %>%  # the .keep argument enables us to remove unnecessary columns.\n    right_join(transcript_features_df, by = \"vlogId\")\n# As with most features, we tried to directly join the created feature to the main dataframe \"transcript_features_df\" by right-joining them.\n\n\n# Sub-Feature: AFINN\n# AFINN Code from \"Introducing Text Analytics: Personality from Text\" to receive keyword list AFINN\ndownload.file(\"http://www2.imm.dtu.dk/pubdb/edoc/imm6010.zip\",\"afinn.zip\")\nunzip(\"afinn.zip\")\nafinn = read.delim(\"AFINN/AFINN-111.txt\", sep=\"\\t\", col.names = c(\"word\",\"score\"), stringsAsFactors = FALSE)\n\ntranscript_features_df <- token_df %>%\n    inner_join(afinn, by = \"word\") %>%\n    group_by(vlogId) %>%\n    summarise(sentiment_afinn = sum(score)) %>%\n    right_join(transcript_features_df, by = \"vlogId\")\n\n\n# Sub-Feature: NRC\n# NRC Code from \"Introducing Text Analytics: Personality from Text\" to receive keyword list NRC\nload_nrc = function() {\n    if (!file.exists('nrc.txt'))\n        download.file(\"https://www.dropbox.com/s/yo5o476zk8j5ujg/NRC-Emotion-Lexicon-Wordlevel-v0.92.txt?dl=1\",\"nrc.txt\")\n    nrc = read.table(\"nrc.txt\", col.names=c('word','sentiment','applies'), stringsAsFactors = FALSE)\n    nrc %>% \n        filter(applies == 1) %>% \n        select(-applies)\n}\n\ntranscript_features_df <- token_df %>%\n    inner_join(load_nrc(), by = \"word\") %>%\n    count(vlogId, sentiment) %>%\n    pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>%\n    mutate(sentiment_nrc = positive - negative, .keep = \"unused\") %>%\n    right_join(transcript_features_df, by = \"vlogId\")\n\n\ntranscript_features_df %>%\n    select(anger:sentiment_bing) %>%\n    head()","metadata":{"execution":{"iopub.status.busy":"2022-09-19T07:59:24.467624Z","iopub.execute_input":"2022-09-19T07:59:24.469017Z","iopub.status.idle":"2022-09-19T07:59:28.184593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature: Average Word and Average Sentence Length.\n\nWe also calculated the average word and average sentence length in vlogger’s transcript. These features came from an idea that individuals with high conscientiousness – being self-disciplined and self-controlled towards their own goals and duties – would tend to use longer words or more elaborate sentences. We thought these individuals tend more towards using difficult or longer words to express themselves. In addition to this, longer sentences not only reflect on difficulty of the sentence but also the use of language in general. We would expect individuals with high conscientiousness to have better rhythmic features in their speech, having more descriptive and explanatory sentences. \n\nAverage Word length was measured as the average amount of characters used per word. Average Sentence length was measured as the average amount of words used per sentence.","metadata":{}},{"cell_type":"code","source":"# FEATURE: \"Average Word Length\" \ntranscript_features_df <- token_df %>%\n    group_by(vlogId) %>%\n    summarise(avg_word_len = nchar(word) %>%\n                                mean()) %>%\n    right_join(transcript_features_df, by = \"vlogId\")\n\n\n# FEATURE: \"Average Sentence Length\" \ntranscript_features_df <- transcripts_df %>%\n    unnest_tokens(sentences, Text, token = \"sentences\") %>%\n    mutate(sentence_num = row_number()) %>%\n    unnest_tokens(words, sentences, token = \"words\") %>% \n    group_by(vlogId) %>%\n    count(sentence_num) %>%\n    summarise(avg_sen_len = mean(n)) %>%\n    right_join(transcript_features_df, by = \"vlogId\")\n# In order to count the words per sentence, we first unnested the text into sentences, gave them numbers, and then unnested into words.\n\ntranscript_features_df %>%\n    select(avg_word_len:avg_sen_len) %>%\n    head()","metadata":{"execution":{"iopub.status.busy":"2022-09-19T07:59:28.187132Z","iopub.execute_input":"2022-09-19T07:59:28.188503Z","iopub.status.idle":"2022-09-19T07:59:29.05707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature: Stopword / Adjective / Linking word / Pronouns / Unique word proportions\n\nWe then calculated the proportions of various word lists from the vlogger’s transcript. As the absolute number of words is generally not a good indicator, we wanted to use proportions to represent the unique use of words in each vlogger’s speech. The stopword is an additive or descriptive feature that occurs in the natural speech, which is considered meaningless and insignificant. The use of stopwords can represent how descriptive the person is and how long it takes the person to get to the main point. It may reflect on person’s conscientiousness, as it shows how organized they are with their words; or, it may show on person’s openness to experience and extraversion, as it reflects confidence in their speech. Adjectives and linking words also represent how descriptive a person is. Adjectives especially show the expressiveness of an individual, showing how frequent the person tries to explain somethings with more explanatory words. The list is extracted from Cambridge dictionary. The use of pronouns, on the other hand, indicate the subjectivity of the speech, showing how frequent the person refers to themselves or others in their vlog. We tried to differentiate personal, first, second, and third pronouns to specifically show which pronouns are correlated with which personality. The pronouns usage also reflects the perspectives of a person. For instance, if a person is more agreeable, he/she will be using more third person pronouns to express the ideas and opinions of others. Lastly, the use of unique words would increase the predictability by being potentially related to conscientiousness. This would show the diversity in the use of language, showing the person is conscious of their words and have control in their speech. We try to improve our model by showing how colorful one’s speech and language is. ","metadata":{}},{"cell_type":"code","source":"# FEATURE: \"Different Word Proportions\" \nwords_df <- token_df %>%\n    group_by(vlogId) %>%\n    summarise(w_num = n())\n\n# Most of the below features were created in a similar fashion: \n# Acquiring a word list, semi-joining into the token dataframe to create a new dataframe containing only the new word types.\n# Afterwards, most were joined with the words_df to calculate the proportions using the absoulte number of words per text.\n\n# Sub-Feature: \"Stopword Proportions\" \nstopwords_df <- token_df %>%\n    semi_join(get_stopwords(), by = \"word\") %>%\n    group_by(vlogId) %>%\n    summarise(s_num = n())\n\ntranscript_features_df <- words_df %>%\n    left_join(stopwords_df, by = \"vlogId\") %>%\n    mutate(stop_prop = s_num/w_num, .keep = \"unused\") %>%\n    right_join(transcript_features_df, by = \"vlogId\")\n\n\n# Sub-Feature: \"Adjectives Proportions\" [List was acquired from this github repo: https://gist.github.com/hugsy/8910dc78d208e40de42deb29e62df913]\nadjective_list <- read.delim(url(\"https://gist.github.com/hugsy/8910dc78d208e40de42deb29e62df913/raw/eec99c5597a73f6a9240cab26965a8609fa0f6ea/english-adjectives.txt\"),\n                             header = FALSE)\nnames(adjective_list) <- paste(\"word\")\n\nadjectives_df <- token_df %>%\n    semi_join(adjective_list, by = \"word\") %>%\n    group_by(vlogId) %>%\n    summarise(a_num = n())\n\ntranscript_features_df <- words_df %>%\n    left_join(adjectives_df, by = \"vlogId\") %>%\n    mutate(adj_prop = a_num/w_num, .keep = \"unused\") %>%\n    right_join(transcript_features_df, by = \"vlogId\")\n\n\n# Sub-Feature: \"Linking Word Proportion\" [List was acquired from https://dictionary.cambridge.org/grammar/british-grammar/conjunctions-and-linking-words]\nlinking_words <- tibble(word = c(\"accordingly\",  \"consequently\", \"for\", \"forthwith\", \"hence\", \"then\", \"therefore\", \"thereupon\", \"thus\",\n                                 \"absolutely\", \"chiefly\", \"clearly\", \"definitely\", \"especially\", \"even\", \"importantly\", \"indeed\", \"obviously\", \n                                 \"particularly\", \"surprisingly\", \"truly\", \"additionally\", \"also\", \"and\", \"besides\", \"finally\", \"first\", \n                                 \"further\", \"furthermore\", \"last\", \"moreover\", \"not only\", \"second\", \"secondly\", \"thirdly\", \"third\",\n                                 \"because\", \"so\", \"example\", \"instance\", \"namely\", \"alternativiely\", \"contrarily\", \"contrary\", \"conversely\", \n                                 \"however\", \"nevertheless\", \"contrast\", \"instead\", \"nonetheless\", \"rather\", \"nor\", \"unlike\", \"while\", \n                                 \"whereas\", \"yet\",\"whilst\", \"alike\", \"both\", \"compare\", \"equally\", \"likewise\", \"altogether\", \"generally\", \n                                 \"conclusion\", \"shortly\", \"summary\", \"overall\", \"but\", \"or\", \"as\"))\n\nlinking_words_df <- token_df %>%\n    semi_join(linking_words, by = \"word\") %>%\n    group_by(vlogId) %>%\n    summarize(l_num = n())\n\ntranscript_features_df <- words_df %>%\n    left_join(linking_words_df, by = \"vlogId\") %>%\n    mutate(link_prop = l_num/w_num, .keep = \"unused\") %>%\n    right_join(transcript_features_df, by = \"vlogId\")\n\n\n# Sub-Feature: \"Unique Word Proportion\"\ntranscript_features_df <- token_df %>%\n    anti_join(get_stopwords(), by = \"word\") %>%\n    group_by(vlogId) %>%\n    summarise(unique_prop = length(unique(word)) / length(word)) %>%\n    right_join(transcript_features_df, by = \"vlogId\")\n\n\n# Sub-Feature: \"Pronouns Proportion\"\nfir_pronouns <- tibble(word = c(\"i'm\", \"i'll\", \"i\",\"my\",\"me\",\"myself\",\"mine\"))\nother_fir_pronouns <- tibble(word = c(\"we\",\"us\",\"ours\",\"our\",\"ourselves\"))\nsec_pronouns <- tibble(word = c(\"you\",\"yourself\",\"yourselves\",\"your\",\"yours\"))\nthi_pronouns <- tibble(word = c(\"she\",\"he\",\"her\",\"him\",\"it\",\"they\",\"them\",\"himself\",\"herself\",\"itself\",\"themselves\",\"his\",\"her\",\"hers\",\"its\",\"their\"))\n\npronouns_df1 <- token_df %>%\n    semi_join(fir_pronouns, by = \"word\") %>%\n    group_by(vlogId) %>%\n    summarize(p1_num = n())\n\npronouns_df2 <- token_df %>%\n    semi_join(other_fir_pronouns, by = \"word\") %>%\n    group_by(vlogId) %>%\n    summarize(p2_num = n())\n\npronouns_df3 <- token_df %>%\n    semi_join(sec_pronouns, by = \"word\") %>%\n    group_by(vlogId) %>%\n    summarize(p3_num = n())\n\npronouns_df4 <- token_df %>%\n    semi_join(thi_pronouns, by = \"word\") %>%\n    group_by(vlogId) %>%\n    summarize(p4_num = n())\n\ntranscript_features_df <- words_df %>%\n    left_join(pronouns_df1, by = \"vlogId\") %>%\n    mutate(pro1_prop = p1_num/w_num, .keep = \"unused\") %>%\n    right_join(transcript_features_df, by = \"vlogId\")\n\ntranscript_features_df <- words_df %>%\n    left_join(pronouns_df2,by = \"vlogId\") %>%\n    mutate(pro2_prop = p2_num/w_num, .keep = \"unused\") %>%\n    right_join(transcript_features_df, by = \"vlogId\")\n\ntranscript_features_df <- words_df %>%\n    left_join(pronouns_df3, by = \"vlogId\") %>%\n    mutate(pro3_prop = p3_num/w_num, .keep = \"unused\") %>%\n    right_join(transcript_features_df, by = \"vlogId\")\n\ntranscript_features_df <- words_df %>%\n    left_join(pronouns_df4, by = \"vlogId\") %>%\n    mutate(pro4_prop = p4_num/w_num, .keep = \"unused\") %>%\n    right_join(transcript_features_df, by = \"vlogId\")\n\n\ntranscript_features_df %>%\n    select(stop_prop:pro4_prop) %>%\n    head()","metadata":{"execution":{"iopub.status.busy":"2022-09-19T07:59:29.061103Z","iopub.execute_input":"2022-09-19T07:59:29.062808Z","iopub.status.idle":"2022-09-19T07:59:30.311399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature: Audiovisual features\n\nAccording to Biel and Gatica-Perez (2012), analysis on the audiovisual features of Youtube Vlogs are useful in identifying and predicting the personality of the vloggers. We’ve decided to use some features from audio cues, such as pitch, the voicing rate, energy (loudness of the voice), the segmentation of the voice, time speaking, and video cues, like looking turns and vlogger’s gaze. The main reason why we’ve only selected these features from the audiovisual file can be found by analyzing Table V and Table VI of Biel and Gatica-Perez (2012), where it displayed the Spearman’s correlation coefficients between audio and video cutes, and the personality traits. Speaking activities in audio cues generally had significant correlations with personality. The feature indicates the fluency and talkativeness of an individual, which possibly relates to extraversion and conscientiousness of the individual. Prosodic cues like intonation and rhythm of the language also showed high correlations with many of the personality traits, as they indicate the intensity and utilization of the language. For instance, the energy of the voice – loudness of the voice – was found to have significant correlations with conscientiousness, extraversion, and agreeableness. This indicates that an individual with a lot of energy in their voice can control their voice, while also showing excitement. From visual features, some of the looking activity and pose features were used, as they indicate how much vloggers are looking at the camera and show confidence in their facial expression. Also, some visual activity features that showed excitement were used, which also indicated some levels of personality traits. Some measures were exlcuded based on non-significant relations to the Big Five.","metadata":{}},{"cell_type":"code","source":"# FEATURE: \"Audiovisual\" \ntranscript_features_df <- read.delim(AudioVisual_file, head = TRUE, sep = \" \") %>%\n    tibble() %>%\n    select(-c(mean.d.energy, mean.spec.entropy, sd.spec.entropy)) %>%\n    right_join(transcript_features_df, by = \"vlogId\")\n\n\ntranscript_features_df %>%\n    select(mean.pitch:hogv.cogC) %>%\n    head()","metadata":{"execution":{"iopub.status.busy":"2022-09-19T07:59:30.314079Z","iopub.execute_input":"2022-09-19T07:59:30.315604Z","iopub.status.idle":"2022-09-19T07:59:30.386488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Some features carried NAs, which we address by inserting 0 at the respective positions","metadata":{}},{"cell_type":"code","source":"# Checking for missing data, where it is, and replacing it with 0\nwhich(is.na(transcript_features_df), arr.ind = TRUE) # checking which rows are affected to get a better picture\ntranscript_features_df[is.na(transcript_features_df)] <- 0\n\nhead(transcript_features_df) ","metadata":{"execution":{"iopub.status.busy":"2022-09-19T07:59:38.536696Z","iopub.execute_input":"2022-09-19T07:59:38.538482Z","iopub.status.idle":"2022-09-19T07:59:38.612185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Once you have computed features from the transcript texts and stored it in a data frame, merge it with the `vlogger_df` dataframe:","metadata":{"_uuid":"f8ba05cf-8815-4bb2-b49b-9eccdd6c2762","_cell_guid":"db396ed9-f94c-48f9-b2ac-1be5792d2a89","trusted":true}},{"cell_type":"markdown","source":"## Feature: Gender\nThe gender feature is included in our analysis because many studies have shown the gender difference in personality traits. For instance, the study by Schmitt et al. (2017) found that the perceived gender roles, socialization, and sociostructural power impact individuals’ behavior as well as their personalities. Especially cultures with larger discrepancies between gender roles and socialization seemed to have larger gender differences in personality. Additionally, they found evidence for differences in conscientiousness and neuroticism. Thus, we think it is essential to have gender as a feature to improve the model predictions. Gender was already included in vlogger_df.","metadata":{}},{"cell_type":"code","source":"# YOUR CODE to merge `vlogger_df` with `transcript_features_df`\nvlogger_df <- vlogger_df %>%\n    left_join(transcript_features_df, by = \"vlogId\")\nhead(vlogger_df)","metadata":{"_uuid":"471f379b-78cb-40bc-a81a-4e74969ec4d6","_cell_guid":"f8532d3c-a6d0-430b-82bc-496bc93587e6","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-19T08:02:33.7184Z","iopub.execute_input":"2022-09-19T08:02:33.720315Z","iopub.status.idle":"2022-09-19T08:02:33.762631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Predictive model\n\nNext you fit your predictive model(s). For instance, a linear regression model that only uses `gender` a feature might be:","metadata":{"_uuid":"54aafd4b-9834-4086-8030-702069f39518","_cell_guid":"ba49ed13-9045-4b21-9f2e-09b58bc02b41","trusted":true}},{"cell_type":"markdown","source":"Initially, we investigated the scatterplots between predictors and response variables to visualize the data for once, get an idea of the variables, and identify possible transformation tragets.\n\nThe code had to be commented out as the figure margins of the plot exceeded the notebooks limit.","metadata":{}},{"cell_type":"code","source":"# pairs(vlogger_df[,-c(1:2)], pch = 1, lower.panel = NULL)","metadata":{"execution":{"iopub.status.busy":"2022-09-18T15:42:08.95503Z","iopub.execute_input":"2022-09-18T15:42:08.956341Z","iopub.status.idle":"2022-09-18T15:42:08.966252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.1 Check for multicollinearity\n\nNext we checked for multicollinearity to identify features that are strongly correlated with eachother. To asses this we computed the variance inflation factor (VIF). \nOur first idea was to exclude all the variables with a VIF higher than 10. However, later on we realised multicollinearity is less problematic than assumed. As our goal concerns prediction, we want to retain as much data and information from features as possible. Furthermore, we plan on doing a stepwise selection  in order to reduce variance and complexity, keeping predictive power. \n\nTherefore, in the end we decided not to remove the variables with a high VIF, also because almost all of the features did not exceed a score of 10.","metadata":{}},{"cell_type":"code","source":"# Custom VIF function\nfor (i in 1:length(vlogger_df[, -c(1:7)])){\n    \n    lmp <- paste(colnames(vlogger_df[, i+7, drop = F]), \"~\", paste(colnames(vlogger_df[,-c(1:7, i+7)]), collapse = \"+\"))\n    fit <- lm(data = vlogger_df, formula = lmp)\n    VIF <- 1/(1 - summary(fit)$r.squared)\n  \n    colnames(vlogger_df[, i+7, drop = F]) %>%\n        paste(VIF, sep = \": \") %>%\n        print()\n}","metadata":{"execution":{"iopub.status.busy":"2022-09-18T15:44:03.996411Z","iopub.execute_input":"2022-09-18T15:44:03.998095Z","iopub.status.idle":"2022-09-18T15:44:04.548422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.2 Fit predictive model\nWe decided to create a model for each personality trait on its own instead of sequentially in a multivariate appraoch. This simplifies the fitting process, enables a stepwise regression approach, and makes the general summaries clearer.\nAdditionally, we decided NOT to use personality traits as predictors for each other, as real-life scenarios most likely won't involve this kind of data and we want to predict the traits solely with the text and audiovisual data at hand.","metadata":{}},{"cell_type":"code","source":"# YOUR CODE to fit your predictive model\n\n# Model Fitting:\nfit_lm_extr <- lm(Extr ~ . -vlogId -Agr -Cons -Emot -Open, data = vlogger_df)\nfit_lm_agre <- lm(Agr ~ . -vlogId -Extr -Cons -Emot -Open, data = vlogger_df)\nfit_lm_cons <- lm(Cons ~ . -vlogId -Agr -Extr -Emot -Open, data = vlogger_df)\nfit_lm_emot <- lm(Emot ~ . -vlogId -Agr -Cons -Extr -Open, data = vlogger_df)\nfit_lm_open <- lm(Open ~ . -vlogId -Agr -Cons -Emot -Extr, data = vlogger_df)\n\n\n# Summary of the five model fits\nsummary(fit_lm_extr)\nsummary(fit_lm_agre)\nsummary(fit_lm_cons)\nsummary(fit_lm_emot)\nsummary(fit_lm_open)","metadata":{"_uuid":"972d1589-1ba3-49b3-bae8-9e09c7666a21","_cell_guid":"8a713b08-df61-4c46-b392-1084c9f357b4","execution":{"iopub.status.busy":"2022-09-18T15:44:14.258255Z","iopub.execute_input":"2022-09-18T15:44:14.259845Z","iopub.status.idle":"2022-09-18T15:44:14.424278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.3 Non-linearity, outliers & leverage points\n\nAfter fitting the model we checked the Residual vs. Fitted plots to identify possible non-linearity of the data. None of the plots showed a clear non-linear associations in the data. \n\nFurthermore, we used  the standardized Residual vs Leverage plot to identify potential outliers and high leverage points (or both!). Although some weak outliers and leverage points can be seen in the plots we decided to not exclude these observations. We don't have many observations and we want to retain as much of our data as possible. We felt comfortable to retain them as they don't appear to be too extreme and did not change the model fit substantially.","metadata":{}},{"cell_type":"code","source":"plot(fit_lm_extr, which = c(1,5))\nplot(fit_lm_agre, which = c(1,5))\nplot(fit_lm_cons, which = c(1,5))\nplot(fit_lm_emot, which = c(1,5))\nplot(fit_lm_open, which = c(1,5))","metadata":{"execution":{"iopub.status.busy":"2022-09-18T15:44:19.436895Z","iopub.execute_input":"2022-09-18T15:44:19.438406Z","iopub.status.idle":"2022-09-18T15:44:21.008704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.4 Stepwise Regression\nWe have a lot of predictors which can lead to an increased variance/lower bias.\n\nIn order to reduce complexity of our models, we decided to use a mixed stepwise regression approach, choosing two criterions to identify a reasonable model fit. The mixed approach enables us to use both mechanisms from forward and backward selection.\n* Both AIC and BIC punish models with too many parameters helping us achive a simpler model fit. \n* However, due to our high sample size, we expect BIC to penalize even more and achieve a more sparse model. This penalty is important, as the AIC fit might be to liberal, ultimately including too many parameters.\n* Therefore, we are going for a more parsimonious model, trying to counter potential overfitting and reduce variance (trading with some bias), while keeping predictive power.\n* We will apply two stepwise regressions to each model, using AIC and BIC as model selection criteria, respectively. Our goal is to find a model that reduces both measures to an acceptable extent.\n* Additionally, the stepwise approach makes sense as the five personality traits might require different combinations of features to be predicted more accurately. ","metadata":{}},{"cell_type":"code","source":"# Stepwise Regression Fitting - AIC (k = 2)\nstep_lm_extr_A <- step(fit_lm_extr, direction = \"both\", trace = 0)\nstep_lm_agre_A <- step(fit_lm_agre, direction = \"both\", trace = 0)\nstep_lm_cons_A <- step(fit_lm_cons, direction = \"both\", trace = 0)\nstep_lm_emot_A <- step(fit_lm_emot, direction = \"both\", trace = 0)\nstep_lm_open_A <- step(fit_lm_open, direction = \"both\", trace = 0)\n\n# Stepwise Regression Fitting - BIC (k = 323 as number of training observations = 323)\nstep_lm_extr_B <- step(fit_lm_extr, direction = \"both\", trace = 0, k = log(323))\nstep_lm_agre_B <- step(fit_lm_agre, direction = \"both\", trace = 0, k = log(323))\nstep_lm_cons_B <- step(fit_lm_cons, direction = \"both\", trace = 0, k = log(323))\nstep_lm_emot_B <- step(fit_lm_emot, direction = \"both\", trace = 0, k = log(323))\nstep_lm_open_B <- step(fit_lm_open, direction = \"both\", trace = 0, k = log(323))\n\n\n# Summary of AIC vs. BIC model selection for all personality dimensions\n# Extraversion\nsummary(step_lm_extr_A)\nsummary(step_lm_extr_B)\n\n# Agreeableness\nsummary(step_lm_agre_A)\nsummary(step_lm_agre_B)\n\n# Conscientiousness\nsummary(step_lm_cons_A)\nsummary(step_lm_cons_B)\n\n# Neuroticism\nsummary(step_lm_emot_A)\nsummary(step_lm_emot_B)\n\n# Openness\nsummary(step_lm_open_A)\nsummary(step_lm_open_B)","metadata":{"execution":{"iopub.status.busy":"2022-09-18T15:44:55.615396Z","iopub.execute_input":"2022-09-18T15:44:55.616977Z","iopub.status.idle":"2022-09-18T15:45:08.108916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"After fitting the stepwise model we first investigated the adjusted R^2, to get an intuition of the explained variance, after adjustment. The adjusted R^2 illustrates a corrected version of the R^2, penalizing the inclusion of less relevant predictors, therefore, being able to decrease.\n\nAs demonstrated by the plots, the AIC-selected models show an increased adj. explained variance, compared to both the initial full models and the BIC-selected models. The model output above confirms this as AIC-selected models have retained more predictors compared to BIC-selected models. This difference, however, is more noticeable for the models concerning the dimensions of Openness and Neuroticism. \n\nWe do not want to select a model solely based on the adj. R^2 value, especially when AIC-selected models contain considerably more predictors than their BIC-model counterparts. Furthermore, differences in the adj. R^2 values are tolerable. ","metadata":{}},{"cell_type":"code","source":"r2_df <- tibble(Extraversion = c(summary(fit_lm_extr)$adj.r.squared, summary(step_lm_extr_B)$adj.r.squared, summary(step_lm_extr_A)$adj.r.squared),\n                Agreeableness = c(summary(fit_lm_agre)$adj.r.squared, summary(step_lm_agre_B)$adj.r.squared, summary(step_lm_agre_A)$adj.r.squared),\n                Conscientiousness = c(summary(fit_lm_cons)$adj.r.squared, summary(step_lm_cons_B)$adj.r.squared, summary(step_lm_cons_A)$adj.r.squared),\n                Neuroticism = c(summary(fit_lm_emot)$adj.r.squared, summary(step_lm_emot_B)$adj.r.squared, summary(step_lm_emot_A)$adj.r.squared),\n                Openness = c(summary(fit_lm_open)$adj.r.squared, summary(step_lm_open_B)$adj.r.squared, summary(step_lm_open_A)$adj.r.squared),\n                Model = c(\"Full Model\", \"BIC Model\", \"AIC Model\"))\nr2_df$Model <- r2_df$Model %>%\n    factor(levels = c(\"Full Model\", \"BIC Model\", \"AIC Model\"))\n\nhead(r2_df)\n\nfor (i in 1:5){\n    \n    p <- ggplot(r2_df, aes_string(fill = \"Model\", y = colnames(r2_df)[i], x = \"Model\")) + \n        geom_bar(position = \"dodge\", stat = \"identity\") + \n        labs(title = paste(\"Comparison of adjusted R^2\", colnames(r2_df)[i], sep =\"\\n\"),\n             x =\"Model\", \n             y = \"adjusted R^2\") +\n        scale_y_continuous(limits = c(0, 0.5), breaks = seq(0, 0.5, by = 0.1)) +\n        scale_fill_brewer(palette = \"Set1\", direction = -1) +\n        theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),\n              panel.background = element_blank(), axis.line = element_line(colour = \"black\"),\n              text = element_text(size = 17), plot.title = element_text(hjust = 0.5))\n    print(p)\n}","metadata":{"execution":{"iopub.status.busy":"2022-09-18T16:26:36.340507Z","iopub.execute_input":"2022-09-18T16:26:36.343129Z","iopub.status.idle":"2022-09-18T16:26:38.709023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To identify the appropriate reduced model, we visualized the AICs and BICs of the respective stepwise models to find the one that reduces both sufficiently. Each graph is comparing the models selected by the AIC vs. BIC criterion on these two values. We intentionally did not visualize the AIC and BIC of the original models as they lead to skewed graphs due to their substantially higher AIC and BIC values. In all cases, the AIC and BIC were reduced by the stepwise regressions. Therefore, in order to clearly compare the two stepwise models and their criteria, we only visualized their AIC/BIC values. \n\nThe below plots of AIC- vs. BIC-selected models show a trend:\n* The BIC-selected models have only a slightly higher AIC compared to the models selected by AIC. \n* In contrast, their BIC is considerably lower.\n* This trend spans over all five personality dimensions\n\nAs all BIC-selected models appear to have a comparatively low AIC and BIC value, we decided to use those models for our predicitons \n\nAdditionally, the AIC-selected models still included too many parameters, risking overfitting by including many pontentially redundant features.","metadata":{}},{"cell_type":"code","source":"stepAB_df <- tibble(Extraversion = c(AIC(step_lm_extr_A), BIC(step_lm_extr_A), AIC(step_lm_extr_B), BIC(step_lm_extr_B)),\n                    Agreeableness = c(AIC(step_lm_agre_A), BIC(step_lm_agre_A), AIC(step_lm_agre_B), BIC(step_lm_agre_B)),\n                    Conscientiousness = c(AIC(step_lm_cons_A), BIC(step_lm_cons_A), AIC(step_lm_cons_B), BIC(step_lm_cons_B)),\n                    Neuroticism = c(AIC(step_lm_emot_A), BIC(step_lm_emot_A), AIC(step_lm_emot_B), BIC(step_lm_emot_B)),\n                    Openness = c(AIC(step_lm_open_A), BIC(step_lm_open_A), AIC(step_lm_open_B), BIC(step_lm_open_B)),\n                    Criterion = c(\"AIC\", \"BIC\", \"AIC\", \"BIC\"),\n                    Model = c(\"AIC Model\", \"AIC Model\", \"BIC Model\", \"BIC Model\"))\nhead(stepAB_df)\n\nfor (i in 1:5){\n    \n    p <- ggplot(stepAB_df, aes_string(fill = \"Criterion\", y = colnames(stepAB_df)[i], x = \"Model\")) + \n        geom_bar(position = \"dodge\", stat = \"identity\") + \n        labs(title = paste(\"Comparison of Stepwise Models\", colnames(stepAB_df)[i], sep =\"\\n\"),\n             x =\"Model\", \n             y = \"Value\") +\n        scale_y_continuous(limits = c(0, 900), breaks = seq(0, 900, by = 100)) +\n        scale_fill_brewer(palette = \"Set1\") +\n        theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),\n              panel.background = element_blank(), axis.line = element_line(colour = \"black\"),\n              text = element_text(size = 17), plot.title = element_text(hjust = 0.5))\n    print(p)\n}","metadata":{"execution":{"iopub.status.busy":"2022-09-18T16:13:23.647207Z","iopub.execute_input":"2022-09-18T16:13:23.649253Z","iopub.status.idle":"2022-09-18T16:13:25.255129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Making predictions on the test set\n\nFor the competition we have to make **predictions** for the data in the **test set**\n\n- The predictions will be evaluated by computing the **Root Means Square Error**:\n    - $\\displaystyle{RMSE =\\sqrt{{1 \\over 5n} \\sum_{k \\in \\{cEXT, \\ldots, cOPN\\}} \\sum_{i=1}^n (y_{ik} - \\hat y_{ik})^2}}$\n    - Here \n        - $y_{ik}$ is the observed value for vlogger $i$ \n        - $\\hat y_{ik}$ is your prediction for vlogger $i$\n        \n        \nYou will have to take the following steps:\n\n1. Extract the test set from the `vlogger_df`\n2. Compute predictions for the test set using your model\n3. Write those predictions to file in the right format\n\nThe following gives code for these steps in order.","metadata":{"_uuid":"04dc5694-5fba-4712-b6a0-5e8ea30ded86","_cell_guid":"d2def0aa-2cf4-47cf-b2f5-31477c6bffda","trusted":true}},{"cell_type":"markdown","source":"## 4.1 The test set\n\nThe test set are those `vlogId` that are missing in the personality scores data frame `pers`. They are the rows in `vlogger_df` for which the personality scores are missing:","metadata":{"_uuid":"f866665f-2c2a-40fa-bf08-fca006375058","_cell_guid":"2862139a-1fb4-4e1f-9136-e610955ef702","trusted":true}},{"cell_type":"code","source":"testset_vloggers = vlogger_df %>% \n    filter(is.na(Extr))\n\nhead(testset_vloggers)","metadata":{"_uuid":"f875910f-552b-4957-8f1a-d434ce9bdbd2","_cell_guid":"1afb86c1-4986-4908-96c3-4b143561363e","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-18T10:48:02.31977Z","iopub.execute_input":"2022-09-18T10:48:02.321143Z","iopub.status.idle":"2022-09-18T10:48:02.35647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.2 Predictions\n\nContinuing the example `fit_mlm` model above, for almost all models we will encounter use the `predict()` function.\n\n- `predict()` function exists for most model fit function like `lm`, `glm`, etc., that we encounter\n    - first argument should be a model object (`fit_mlm` in the example)\n    - second argument should be a data frame with the test set\n    - optionnaly, a third argument specifies type of response:\n      - for `lm` object only `type = \"resp\"`\n      - for `glm` object `type = \"pred\"` (linear predictor) or `type = \"resp\"` ('response' &rarr; probabilities)\n","metadata":{"_uuid":"d4c0a598-8241-4d91-a60b-cc964318422d","_cell_guid":"560128db-06d2-493a-9b78-9fa2ff25881f","trusted":true}},{"cell_type":"markdown","source":"As mentioned above, due to having five different models, we also have to predict five separate times. In this case, our analysis concluded to use the stepwise regression model suggested by the BIC criterion. Compared to the models selected by AIC, the BIC-models showed low AIC and BIC values, reducing the complexity considerably and retaining an acceptable adjusted R^2. All personality dimensions have an individual prediction model, including different features for the respective predictions. ","metadata":{}},{"cell_type":"code","source":"pred_extr <- predict(step_lm_extr_B, new = testset_vloggers)\npred_agre <- predict(step_lm_agre_B, new = testset_vloggers)\npred_cons <- predict(step_lm_cons_B, new = testset_vloggers)\npred_emot <- predict(step_lm_emot_B, new = testset_vloggers)\npred_open <- predict(step_lm_open_B, new = testset_vloggers)\n\n# Always check the output\nhead(pred_extr)\nhead(pred_agre)\nhead(pred_cons)\nhead(pred_emot)\nhead(pred_open)","metadata":{"_uuid":"9263474a-b2a7-4073-88e4-57af25295b0f","_cell_guid":"9453537e-1d01-45a9-bfb7-b91b891e7b1e","execution":{"iopub.status.busy":"2022-09-18T10:56:00.273654Z","iopub.execute_input":"2022-09-18T10:56:00.279274Z","iopub.status.idle":"2022-09-18T10:56:00.369092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# compute output data frame\ntestset_pred = testset_vloggers %>% \n    mutate(\n        Extr = pred_extr, \n        Agr  = pred_agre,\n        Cons = pred_cons,\n        Emot = pred_emot,\n        Open = pred_open\n    ) %>%\n    select(vlogId, Extr:Open)\n\nhead(testset_pred)","metadata":{"_uuid":"c3543421-d7bd-42ea-a880-23825de5f8bc","_cell_guid":"873a1bde-0f8e-446d-8153-5681e6d27134","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-18T10:48:02.418893Z","iopub.execute_input":"2022-09-18T10:48:02.420313Z","iopub.status.idle":"2022-09-18T10:48:02.452004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.3 Writing predictions to file\n\nYou need to upload your predictions in .csv file. However, there are multiple columns: `Extr`, `Agr`, `Cons`, `Emot`, `Open`, while Kaggle expects **long format**!\n\nWhat does long format look like?\n\n- Every prediction on a single line.\n- Columns `vlogId` and `pers_axis` to map prediction *vlogger ID* and *personality axis*.\n\nTo achieve this, first `gather` the column values into a single `value` column, adding a `pers_axis` to indicate the column name:","metadata":{"_uuid":"2ef3a62f-62cf-42ca-9f50-c07a93d04ccf","_cell_guid":"4528893d-1930-4ccf-b4c0-51a0c773dae5","trusted":true}},{"cell_type":"code","source":"testset_pred_long  <- \n  testset_pred %>% \n  gather(pers_axis, Expected, -vlogId) %>%\n  arrange(vlogId, pers_axis)\n\nhead(testset_pred_long)","metadata":{"_uuid":"7697fa94-f0fd-4668-a0db-bbf98c7199a0","_cell_guid":"03cecf1d-4780-4764-bf18-00da7fd22984","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-18T10:48:02.454577Z","iopub.execute_input":"2022-09-18T10:48:02.455977Z","iopub.status.idle":"2022-09-18T10:48:02.488236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"According to the competition's [Evaluation instructions](https://www.kaggle.com/c/bda2019big5/overview/evaluation), Kaggle expects file with two colums: `Id` and `value`.\n  \nThe [Evaluation instructions](https://www.kaggle.com/c/bda2019big5/overview/evaluation) specifies we need to encode the `Agr` prediction for `VLOG8` as `VLOG8_Agr` in the `Id` column. To achieve this use `unite()` function of `dplyr`.\n\n`unite()` take:\n\n- a data frame as its first argument (implicitely passed by the piping operator `%>%`)\n- the name of new column as its second argument (`Id` below)\n- all extra arguments (`vlogId` and `pers_axis` below) are concatenated with an underscore in between\n\nThen write the resulting data frame to a .csv file.","metadata":{"_uuid":"229b46a3-ff86-463d-ba3a-d91ce5e44b89","_cell_guid":"e62e1252-b466-424a-9edd-c6e71131dd95","trusted":true}},{"cell_type":"code","source":"# Obtain the right format for Kaggle\ntestset_pred_final <- \n  testset_pred_long %>%\n  unite(Id, vlogId, pers_axis) \n\n# Check if we succeeded\nhead(testset_pred_final)\n\n# Write to csv\ntestset_pred_final %>%\n  write_csv(file = \"predictions.csv\")\n\n# Check if the file was written successfully.\nlist.files()","metadata":{"_uuid":"4a729773-ad88-4830-9c24-f0893a61d381","_cell_guid":"84498e3c-77cc-4434-a91f-a099e72c93dd","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-17T18:14:06.865654Z","iopub.execute_input":"2022-09-17T18:14:06.867195Z","iopub.status.idle":"2022-09-17T18:14:06.927565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Once you have clicked the <span style=\"background-color:#000000;color:white;padding:3px;border-radius:10px;padding-left:6px;padding-right:6px;\">⟳ Save Version&nbsp;&nbsp;|&nbsp;&nbsp;0</span> button at the top left, and select the \"Save & Run All (Commit)\" option, go to the Viewer. There you will find your \"predictions.csv\" under Output. You'll also see a button there that allows you to submit your predictions with one click.","metadata":{"_uuid":"ceb46677-aa88-4b59-b6fe-1a6ea5afd432","_cell_guid":"d440c5a9-2554-4618-bdae-ae2625df13ef","trusted":true}},{"cell_type":"markdown","source":"## Sources\n\n* Biel, J. I., & Gatica-Perez, D. (2012). The youtube lens: Crowdsourced personality impressions and audiovisual analysis of vlogs. IEEE Transactions on Multimedia, 15(1), 41-55.\n* Schmitt, D. P., Long, A. E., McPhearson, A., O'Brien, K., Remmert, B., & Shah, S. H. (2017). Personality and gender differences in global perspective. International Journal of Psychology, 52, 45-56.","metadata":{}}]}