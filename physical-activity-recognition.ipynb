{"metadata":{"kernelspec":{"name":"ir","display_name":"R","language":"R"},"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"4.0.5"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction to Physical Activity Recognition \n\nThis project aims to find statistical algorithms to detect and recognize physical activities of human using smartphones. The learning algorithms are based on classification models, using diverse unique extracted features. The current notebook includes following steps:\n1. Reading the data that includes 12 different activities and different signals per activity and per participant. \n2. Feature extraction that considers both standardized and unstandardized features based on histogram, statistical analyses, and literatures.\n3. Data cleaning to remove features that have near zero variation, high correlations, and multicollinearity.\n4. Model fitting: LDA, Multinomial-LDA, KNN, Stepwise Regression, other cross validations. & Model Comparison to choose the best model that predicts the variable most accurately. \n5. Conclusion gives the overview of our work and reason why we chose the final model.\n* Refer to the bottom of the page to see the contribution of the members.\n\n","metadata":{}},{"cell_type":"markdown","source":"# Data Preparation\n### Installing tidyverse package and reading datasets from files","metadata":{}},{"cell_type":"code","source":"#run tidyverse: the basis package for the current competition\nlibrary(tidyverse) \nlist.files(path = \"../input\")\n.... = NA","metadata":{"_uuid":"93de3694eaabf3b22b62e4876069a9cf8f92fb7e","_execution_state":"idle","execution":{"iopub.status.busy":"2022-09-28T15:14:15.48158Z","iopub.execute_input":"2022-09-28T15:14:15.483676Z","iopub.status.idle":"2022-09-28T15:14:15.510695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make sure the data is available\nif (length(list.files(\"../input\", pattern = \"recognition\")) > 0) {\n    \n    # Copy all files to the current directory\n    system(\"cp -r ../input/bda2022signals/* ./\")\n    \n} else {\n    \n    # Download data for this competition\n    data_url = \"https://phonesensordata.netlify.app/Archive.zip\"\n    download.file(data_url, \"Archive.zip\")\n\n    # Unzip all files in the current directory\n    unzip(\"Archive.zip\")\n}\n\n# list files in the current working directory\nlist.files()\n\n# show the content of the labels file \nfile.show(\"activity_labels.txt\")","metadata":{"_uuid":"c6073784c036efe22d6d5cc50d5e941dd039e7ee","execution":{"iopub.status.busy":"2022-09-28T15:14:17.044987Z","iopub.execute_input":"2022-09-28T15:14:17.046655Z","iopub.status.idle":"2022-09-28T15:14:19.713592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train and Test folder are located in the RawData folder\nlist.files(\"./RawData\")\n\n# The Train folder contains 85 files:\nlength(list.files(\"./RawData/Train\"))\n\n# A sample of the file names in the Train folder; notice the filename pattern\nset.seed(1)\nsample(list.files(\"./RawData/Train\"),6)","metadata":{"execution":{"iopub.status.busy":"2022-09-28T15:14:19.716113Z","iopub.execute_input":"2022-09-28T15:14:19.717528Z","iopub.status.idle":"2022-09-28T15:14:19.747985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n# 1. Reading the data\n\n## 1.1 Import Activity labels\n\nFirst import the activity labels:","metadata":{"_uuid":"968c9a784fa2d6ebd271ccb31a9c5cdc41175f25"}},{"cell_type":"code","source":"# store the signals for each user for each experiment \n# stores the activity labels for segments of signals\n\nact_labels = read_delim(\"activity_labels.txt\",\" \",col_names=FALSE,trim_ws=TRUE) \nact_labels = act_labels %>% select(X1,X2)\nact_labels ","metadata":{"_uuid":"f8fb07fb5ea7520789d0fb55afe4bfc555083bb6","execution":{"iopub.status.busy":"2022-09-28T15:14:21.244225Z","iopub.execute_input":"2022-09-28T15:14:21.245828Z","iopub.status.idle":"2022-09-28T15:14:21.359967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# stores the trial number, user ID, activity together with the sample number\nlabels = read_delim(\"./RawData/Train/labels_train.txt\", \" \", col_names = F)\ncolnames(labels) <- c('trial', 'userid', 'activity', 'start', 'end')\n\nlabels = labels %>% mutate(activity = act_labels$X2[activity])\n\n#labels of the dataset\nprint(labels)","metadata":{"_uuid":"7076c372a40933c42af18e4e906abc3df6d453d1","execution":{"iopub.status.busy":"2022-09-28T15:14:25.670035Z","iopub.execute_input":"2022-09-28T15:14:25.671871Z","iopub.status.idle":"2022-09-28T15:14:25.822602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1.2 Import the signals\n\nFirst look at participant with `userid` = 1, `trial` = 1 and see how we can import the signals, and then label each sample in the signal with the activity labels stored in the `labels` data frame.","metadata":{"_uuid":"999173cbb57a05233f5b70f9c89a4eee6efee205"}},{"cell_type":"code","source":"# identify the file name and extract the 'username' (participant ID) and 'expname' (experimental trial)\nfilename = \"RawData/Train/acc_exp01_user01.txt\"\nusername = gsub(\".+user(\\\\d+).+\", \"\\\\1\", filename) %>% as.integer()\nexpname  = gsub(\".+exp(\\\\d+).+\", \"\\\\1\", filename) %>% as.integer()\n\n# import the data from the file\nuser01 = read_delim(filename, \" \", col_names = F)\nhead(user01) #check nothing went wrong","metadata":{"_uuid":"8df88fc28ee2a3a96083f53c1170e2dc2808bd4d","execution":{"iopub.status.busy":"2022-09-28T15:14:28.256511Z","iopub.execute_input":"2022-09-28T15:14:28.258339Z","iopub.status.idle":"2022-09-28T15:14:28.37622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Each column is a signal. Subsequent rows are subsequent measurement samples, and so we treat rownumber as a time indicator (to keep the distinction clear we'll talk about sample number).\n\nChecking signal wave forms:","metadata":{"_uuid":"15ba83f20a918d1d65823362bdee3273e0abadbd"}},{"cell_type":"code","source":"options(repr.plot.width=12)\n\nplot.ts(user01, xlab=\"Sample number\")","metadata":{"_uuid":"73ffda5bf0270f117874e94b1439b16730fddb3b","execution":{"iopub.status.busy":"2022-09-28T15:14:30.870408Z","iopub.execute_input":"2022-09-28T15:14:30.872132Z","iopub.status.idle":"2022-09-28T15:14:31.437688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Note: Different segments from horizontal axis correspond to different activities\n\n\n## 1.3 Merging Signals and Labels\nMerging data frame to have an acitivty label for each `trial`, `userid` and each time `sampleid` that has matching rows for each row in the signals data frame. ","metadata":{"_uuid":"6781f50084a24a9e05cc6b4240b63352177a3ee7"}},{"cell_type":"code","source":"# Add the sequence start:end to each row in a list.\n# The result is a nested table:\nsample_labels_nested = \n    labels %>% \n    rowwise() %>% # do next operation(s) rowwise\n    mutate(sampleid = list(start:end)) %>%\n    ungroup()\n\n# Check the resulting table:\nprint(sample_labels_nested, n=6) ","metadata":{"execution":{"iopub.status.busy":"2022-09-28T15:14:34.48066Z","iopub.execute_input":"2022-09-28T15:14:34.482459Z","iopub.status.idle":"2022-09-28T15:14:34.546441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Note that dplyr prints only a summary of the 'sampleid' column, in a rather abstract way (e.g., `<int [983]>` under `sampleid` means: `sampleid` contains 983 integers for row 1).\n\n\nNext we unnest the nested tibble `sample_labels_nested` to obtain a table that for each `sampleid` value stores the right `activity` label. Before unnesting, to solve issue of each roow corresponding to a signal segment of an activity, we'll add the row numbers as `segment` ID:\n","metadata":{}},{"cell_type":"code","source":"# Unnest the nested tabel.\nsample_labels = \n    sample_labels_nested %>% \n\n    # Rows are segments, we need to keep track of different segements\n    mutate(segment = row_number() ) %>% \n\n    # Expand the data frame to one sample per row\n    unnest(cols = c(sampleid)) %>% \n\n    # Remove columns we don't need anymore\n    select(-start, -end) \n\n\n# Check the result (first few rows are not interesting; rows 977-990 are)\nprint(sample_labels[977:990, ])","metadata":{"execution":{"iopub.status.busy":"2022-09-28T15:14:37.193691Z","iopub.execute_input":"2022-09-28T15:14:37.195344Z","iopub.status.idle":"2022-09-28T15:14:37.268832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now that we have each sample labeled with an activity, we can add the corresponding signals values that are stored in `user01`:","metadata":{}},{"cell_type":"code","source":"user_df = \n    # Store signals user01 in a data frame, with 'userid' and 'trial'\n    data.frame(userid = username, trial = expname, user01) %>%\n\n    # Add 'sampleid' for matching the sampleid's in 'sample_labels'. \n    # The first sample in user01 signals always has sampleid=0; the last\n    # has sampleid is therefore nrow(user01)-1.\n    mutate(sampleid = 0:(nrow(user01)-1) ) %>%\n\n    # Add the labels stored in sample_labels\n    left_join(sample_labels) \n\n# Check the result (first few rows are not interesting; the following are)\nprint(user_df[1227:1239, ])","metadata":{"execution":{"iopub.status.busy":"2022-09-28T15:14:40.013551Z","iopub.execute_input":"2022-09-28T15:14:40.015363Z","iopub.status.idle":"2022-09-28T15:14:40.232968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Visualize the result by using `ggplot()` which allows to give different signal segments different colors to label the activity in that segment:","metadata":{"_uuid":"f4634c660f2ac3a81cc41c18a846a221a23ec24a"}},{"cell_type":"code","source":"options(repr.plot.width=15) # change plot width for nicer output\n\nuser_df %>% \n  ggplot(aes(x = sampleid, y = X1, col = factor(activity), group=segment)) + \n      geom_line()  ","metadata":{"_uuid":"c088b1d7fae494708b2a1339dcfeb4c790e1c662","execution":{"iopub.status.busy":"2022-09-28T15:14:45.865774Z","iopub.execute_input":"2022-09-28T15:14:45.86768Z","iopub.status.idle":"2022-09-28T15:14:46.808129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*Note: In the plot you'll notice the weird gray lines crossing through the plot. The gray trace corresponds to non-labeled segments (labeled `NA` in the legend of the plot). The segments that are labeled with an activity are interspersed with short unlabeled segments, which are drawn in gray, which causes the gray trace to connect different unlabeled segments.*\n\nNotice that some samples have been labeled `NA`, meaning _any activity that is not on the list_. Whole sections of signal consist of this unlisted activity.\n\n\n# 2. Feature Extraction\n\nFollowing plot shows segments with typical walking cycles, and that time samples themselves are not useful features:\n\n1. that we don't know how long the typical pattern is (i.e., how many samples it spans), and \n2. that the pattern may be shifted relative to the start of our time window so that it appears _shifted_ \n","metadata":{"_uuid":"903d9aabb30f663db30ee64963d4165f6ad8a14f"}},{"cell_type":"code","source":"user_df %>% \n\n  # change 7986 to 8586 to see shifted walk cycle\n  dplyr::filter(activity == \"WALKING\", segment == 13, \n    7596 < sampleid & sampleid < 7986) %>% \n\n  ggplot(aes(x = sampleid %% 54, y = X1, group = sampleid %/% 54, \n             col = factor(sampleid %/% 54))) + geom_line() ","metadata":{"_uuid":"0ab6f32884db6d8778e2c0d2df72a72f12b30f3d","execution":{"iopub.status.busy":"2022-09-28T15:15:01.427342Z","iopub.execute_input":"2022-09-28T15:15:01.429348Z","iopub.status.idle":"2022-09-28T15:15:02.021743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Thus, what we have to do is compute features that are (more or less) invariant to time shifts by ignoring the time order of the values and look at them as a collection of numbers. The best way to look at unordered collections of numbers is to look at statistical summaries.\n\nBelow is the histograms of the signal samples per activity:","metadata":{"_uuid":"feaf4c1ec233ee5d6f4ae5e9d78c6026682daf46"}},{"cell_type":"code","source":"user_df %>%\n    ggplot(aes(X1)) + \n      geom_histogram(bins=40, fill=1, alpha=0.5) + \n      geom_histogram(aes(X2), bins=40, fill = 2, alpha=0.5) + \n      geom_histogram(aes(X3), bins=40, fill = 4, alpha=0.5) +\n      facet_wrap(~activity, scales = \"free_y\")","metadata":{"_uuid":"6cd88ca53e9a572fe5f9cd02e01f726029dd7544","execution":{"iopub.status.busy":"2022-09-28T15:15:04.696842Z","iopub.execute_input":"2022-09-28T15:15:04.698407Z","iopub.status.idle":"2022-09-28T15:15:07.499086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Epochs\n\nNow there's one other thing concerning these signals: The signals have different activities at different times, and in general, we don't know when an activity is going to start or end. \n\nIn the Test data set you will be asked to predict the activities in subsequent time windows, called _epochs_, of 128 samples (=128 / 50Hz = 2.56 sec). So you will also have to train a prediction algorithm on the signals that are segmented into _epochs_ of 128 samples.\n\nWe use this trick to group the rows in `user` into epochs, and then compute summary statistics per epoch. The result is a data frame with as many rows as there are epochs, and on each row the summary statistics computed. ","metadata":{"_uuid":"7fe5fd192ef188b802081cc59f7df7bdb3f3053e"}},{"cell_type":"code","source":"user_df %>%\n  # add an epoch ID variable (on epoch = 2.56 sec)\n  mutate(epoch = sampleid %/% 128) %>% \n  # group by 'epoch'\n  group_by(epoch) %>%\n  # compute mean features and standard deviation features\n  summarise(mean_X1 = mean(X1), mean_X2 = mean(X2), mean_X3 = mean(X3)) %>%\n  # inspect the first 6 epochs\n  head()","metadata":{"execution":{"iopub.status.busy":"2022-09-28T15:15:46.442446Z","iopub.execute_input":"2022-09-28T15:15:46.444121Z","iopub.status.idle":"2022-09-28T15:15:46.489002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"What we did here was the following\n\n1. We divided up the samples into 'epochs' (and computed an 'epoch' id),\n2. we then grouped the resulting data frame by 'epoch' id,\n3. and then we computed the mean of the signal samples in each epoch, for each of the 3 signals","metadata":{}},{"cell_type":"markdown","source":"## 2.1 Functions for Feature Extraction\n\n### FEATURE DESCRIPTIONS ###\n\n#### Time domain features:\n\nTime domain features are included in general to detect the time aspect of the signals, showing the signal changes over time. These below features show more of in-depth interpretation of signals changes over time. For instance, correlations and autocorrelations would quantify the changes.\n\n* **_Level_**: It simply indicate the mean across the samples of a signal. It can inform the changes over time by detecting the dynamics in mean signals.\n* **_Power_**: It represents the average squared amplitude of the signal. Power reflects the loudness of the signal, indicating the deviation from an absolute zero of X. The loudness may differ in different activities, as the strength of each activty differs. \n* **_Energy_**: It is the total power of the n samples. It may aid on distingushing between activities as the power of the signals all differ per activity. \n* **_Entropy_**: It interprets the average surprise of an observed value from histogram. The differences show by how low or high the probabililties are: the higher the probability, the less 'surprised' you are. \n* **_Autocorrelation_**: It is interesting to extract because it aids differentiating activities; for instance, slowly changing signals have high autocorellations, while fast changing signals have low or even negative autocorrelations.\n* **_Correlation_**: They also show differences by showing the changes from one point to another; if they have high correlation, it indicates the slow changes, while high correlation shows fast changes.\n\n\n#### Sub-Time domain Features - Statistical features:\n\nHistograms give a detailed picture of the distribution of the numbers that make up the signal. Based on this, we will be extracting a less detailed characterization of the distribution, such as their location of the distribution (i.e., the _mean_), and the width of the distribtuion (_standard deviation_). These features show differences in general signals or wave forms, which could help differentiating between activities. These simple statistical summary measures often yield good predictive features. We used the following histogram features:\n* _Mean_, _Standard Deivations_, _Quantiles_, _Skewness_, _Median_, _Mode_, _Maximum and Minimum_, _Kurtosis_\n* _Standard Error_, _Root Mean Squared_\n\n#### Frequency domain features: \n\nFrequency domain features show how signals are presented over each frequency band. This could be detected by signal spectrum that compares between different activities in each frequency band. \n\n* **_Mean frequency_**: We used general mean frequency to find which activity has higher mean frequency and what not. \n* **_Spectral peak, spectral mean frequency, spectral standard deviation, spectral entropy_**:\n    - The spectrum of a signal shows which frequencies a signal is composed of. It shows the number of fluctuations, including signals like a walking patterns ... etc. Peaks show the strength in which peaks are presented. Notice that height of each frequency is the square of a linear regression coefficient, meaning we can use to predict the signals from a wave. These spectral features can be used as a probability density function as well (ex, mean frequency). \n \n#### Other features:\n \n* **_Convolutions_**: For pattern recognition we used convolution. Convolution is a filter that passes over for example an image and extracting features that show a commonolatity in the image (signals) such that if the image has certain features, it belongs to a particular class. Thus, aiding in detecting activity. \n* **_Zero crossings_**: It measures how many times the waveform crosses the zero axis. With zero crossing we are able to see whether the sign of a signal changed. Since our goal is to distinguish different physical activities this can be useful. \n* **_Coefficient variance_**: It is the spread of the values in the epoch. The differences in values can be an indication of which signals in each epoch are different per activities. \n* **_Width/heigth ratio_**: It is the ratio of width and height of the wave. This is an unstandardized method, which we aim to learn the differences in proportion of width and heigh of each signals per activity. \n* **_Signal Magnitude Area (SMA)_**: statistical measure of the magnitude of a varying quantity that shows indication of different area in each signal.\n\n#### Features we did not use:\n\n* **_Amount of peaks_**: Here we counted the amount of peaks that could be found in the epoch, as in different activities, we can see different amount of peaks. We thought it could be a good predictor for detecting which activity belongs to how many amount of peaks.\n* **_Difference between highest and lowest peak_**: As seen in one of the earlier diagrams you can see that sitting has a small difference between signals while wallking has a lot higher peaks then their valleys so this could help define the different classes.\n* **_Average distance between the valleys_**: The amount of time that passed between signals also seemed to differ accros the different classes. So here we look at the distance between valleys and average it.","metadata":{}},{"cell_type":"markdown","source":"#### References\n* Reyes-Ortiz, J. L., Oneto, L., SamÃ , A., Parra, X., & Anguita, D. (2016). Transition-aware human activity recognition using smartphones. Neurocomputing, 171, 754-767. DOI:10.1016/j.neucom.2015.07.085\n* Grasman, R. (2018). Feature extraction from Signals. DropBox. https://paper.dropbox.com/doc/Feature-extraction-from-Signals-qCp5uvj47gmyuw5nmB8lL\n* https://rug.mnhn.fr/seewave/HTML/MAN/zcr.html https://ieeexplore.ieee.org/document/540290 https://www.sciencedirect.com/topics/engineering/zero-crossing-rate\n* https://rpubs.com/eR_ic/conv_pools","metadata":{}},{"cell_type":"markdown","source":"### FUNCTION CREATION ###\n\nFeatures function are created to aid the calculation simplification. Below are the functions listed in the order of time domain, statistical, frequency, and other features.\n> The built-in functions are excluded from the below block, but only in the 'Step 3: Putting it all together' step.","metadata":{}},{"cell_type":"code","source":"# Helper functions\nmost_common_value = function(x) {\n    counts = table(x, useNA='no')\n    most_frequent = which.max(counts)\n    return(names(most_frequent))\n}\n\n#### TIME DOMAIN FEATURES ####\n\n# Level function\nlev_fun <- function(x){\n    lev = (1/length(x)) * sum(x)\n    return(lev)\n}\n\n# Energy function\nenergy_fun = function(x) {\n    ener = sum((x - mean(x))^2) \n    return(ener)\n}\n\n# Entropy function\nent_fun  <- function(x, nbreaks = nclass.Sturges(x)) {\n    r = range(x)\n    x_binned = findInterval(x, seq(r[1], r[2], len= nbreaks))\n    h = tabulate(x_binned, nbins = nbreaks) # fast histogram\n    p = h/sum(h)\n    -sum(p[p>0] * log(p[p>0]))\n}\n\n# Autocorrelation function\nlagged_cor = function(x, y=x, lag=0) {\n    # compute correlation between x and a time shifted y\n    r_lagged = cor(x, dplyr::lag(y, lag), use='pairwise')\n    r_lagged = ifelse(is.na(r_lagged),0,r_lagged)\n    return(r_lagged)\n}\n\n#### STATISTICAL FEATURES ####\n\n# Interquartile Range function\niqr_fun <- function(x) {\n    iqr = quantile(x, .75) - quantile(x, .25)\n    return(iqr)\n}\n\n# Mode function\nmode_fun <- function(x) {\n    mode = as.integer(which.max(table(x)))\n    return(mode)   \n}\n\n# Standard Error function\nse_fun <- function(x) {\n    se = sd(x) / sqrt(length(x))\n    return(se)\n}\n\n# Root Mean Square function\nrms_fun <- function(x){ #only on vectors\n    rms = sqrt((1/length(x)*(sum(x^2))))\n    return (rms)\n}\n\n#### FREQUENCY DOMAIN FEATURES ####\n\n# Mean Frequency function\nmean_freq <- function(x) {\n    out_1 = numeric()\n    for (i in 1:length(x)){\n        out_1[i] = i * x[i] }\n        return(sum(out_1)/sum(x))\n}\n\n#Spectral Peak function\nspec_peak = function(x) {\n    spec = spectrum(x, log = 'n', plot = FALSE)\n    peak = spec$freq[which.max(spec$spec)]\n    return(peak)\n}\n\n# Spectral Mean Frequency function\nspec_mean_freq <- function(x) {\n    spec = spectrum(x, log = 'n', plot = FALSE)\n    df = spec$freq[2] - spec$freq[1]\n    sbar = sum(spec$freq * spec$spec * df)\n    return(sbar)\n}\n\n# Sepctral Standard Deviation function\nspec_sd <- function(x) {\n    spec = spectrum(x, log = 'n', plot = FALSE)\n    df = spec$freq[2] - spec$freq[1]\n    svar = sum((spec$freq - mean(x))^2 * spec$spec * df)\n    return(svar)\n}\n\n# Spectral Entropy function\nspec_ent <- function(x) {\n  spec = spectrum(x, log='n', plot = FALSE)$spec\n  ent_fun(spec)\n}\n\n#### OTHER FEATURES ####\n\n# Pattern detection by convolutional neural networks function\nconv_fun <- function(x, m) {\n    w = 1/(2*m+1)\n    conv = max(stats::filter(x, w, method = 'convolution'))\n    return(conv)\n}\n\n# Signal Magnitude (SMA) function\nsma_fun <- function(x1,x2,x3){\n    sma <- (1/3) * sum(abs(c(x1,x2,x3)))\n    return(sma) }","metadata":{"_uuid":"6cec2d0fa3e99e2d924c24ac55c5d462ae666707","execution":{"iopub.status.busy":"2022-09-28T15:16:09.385365Z","iopub.execute_input":"2022-09-28T15:16:09.387629Z","iopub.status.idle":"2022-09-28T15:16:09.441252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"What we did here is following:\n1. Build functions that will necessarily simplify the feature extraction process (or simplify the codes)\n2. Without using many packages, build unique functions based on mathematical formulas of the function from literatures and slides (see above for citation lists)\n3. Divide each section based on statistical, histogram based, time domain, frequency domain, and other (not-defined) features\n\nNow we'll be extracting/ computing features per epoch.","metadata":{}},{"cell_type":"markdown","source":"# 3. Putting it all together\n\nAll the manual and built-in functions are applied to the below feature extraction process. \nAll the functions are divided into four sections, in the order of time domain, statistical, frequency, and other features.\n","metadata":{"_uuid":"70f82939d0025cd90b72ea9b46b23c9a110f4f38"}},{"cell_type":"code","source":"extractTimeDomainFeatures <- function(filename, sample_labels) {\n    \n    # extract user and experimental run ID's from file name\n    username = gsub(\".+user(\\\\d+).+\", \"\\\\1\", filename) %>% as.numeric()\n    expname  = gsub( \".+exp(\\\\d+).+\", \"\\\\1\", filename) %>% as.numeric()\n    \n    # import the sensor signals from the file\n    user01 <- read_delim(filename, \" \", col_names = F, progress = TRUE, \n                 col_types = \"ddd\")\n    \n    # merge signals with labels \n    user_df <- \n        data.frame(userid = username, trial = expname, user01) %>%\n        mutate(sampleid = 0:(nrow(user01)-1) ) %>%\n        left_join(sample_labels, by = c('userid','trial','sampleid')) \n\n    \n    # split in epochs of 128 samples and compute features per epoch\n    usertimedom <-  user_df %>%\n    \n          # add an epoch ID variable (on epoch = 2.56 sec)\n          mutate(epoch = sampleid %/% 128) %>% \n\n          # extract statistical features from each epoch\n          group_by(epoch) %>%\n          summarise(\n              \n            # keep track of user and experiment information\n            user_id = username, \n            exp_id = expname,   \n              \n            # start sample\n            sampleid = sampleid[1],\n            \n            # keep track of signal lengths\n            n_samples = n(),\n            \n            # epoch's activity labels\n            activity = most_common_value(c(\"-\", activity)),\n              \n            # Computing time domain features: \n              ## Level:\n              level1 = lev_fun(X1),\n              level2 = lev_fun(X2),\n              level3 = lev_fun(X3),\n\n               ## Power:\n              power1 = mean(X1^2),\n              power2 = mean(X2^2),\n              power3 = mean(X3^2),\n              \n              ## Energy:\n              energy1 = energy_fun(X1),\n              energy2 = energy_fun(X2),\n              energy3 = energy_fun(X3),\n              \n              ## entropy:\n              ent_1 = ent_fun(X1),\n              ent_2 = ent_fun(X2),\n              ent_3 = ent_fun(X3),\n              \n              ## autocorrelation:\n                  ### computing for lag = 1\n                  AR1_1 = lagged_cor(X1, lag = 1),            \n                  AR2_1 = lagged_cor(X2, lag = 1), \n                  AR3_1 = lagged_cor(X3, lag = 1),\n                  AR12_1 = lagged_cor(X1, X2, lag = 1),\n                  AR13_1 = lagged_cor(X1, X3, lag = 1),\n                  AR23_1 = lagged_cor(X2, X3, lag = 1),\n\n                  ### computing for lag = 2\n                  AR1_2 = lagged_cor(X1, lag = 2),            \n                  AR2_2 = lagged_cor(X2, lag = 2), \n                  AR3_2 = lagged_cor(X3, lag = 2),\n                  AR12_2 = lagged_cor(X1, X2, lag = 2),\n                  AR13_2 = lagged_cor(X1, X3, lag = 2),\n                  AR23_2 = lagged_cor(X2, X3, lag = 2),\n              \n              ## Pearson correlation coefficient:\n              cor12 = cor(X1, X2, method = \"pearson\", use = \"complete.obs\"),\n              cor13 = cor(X1, X3, method = \"pearson\", use = \"complete.obs\"),\n              cor23 = cor(X2, X3, method = \"pearson\", use = \"complete.obs\"),\n\n            # Computing statistical features:\n              ## mean:\n              m1 = mean(X1), \n              m2 = mean(X2),\n              m3 = mean(X3),\n\n              ## standard deviations:\n              sd1 = sd(X1), \n              sd2 = sd(X2),\n              sd3 = sd(X3),\n\n              ## quantiles:\n              q1_25 = quantile(X1, .25),\n              q2_25 = quantile(X2, .25),\n              q3_25 = quantile(X3, .25),\n              q1_75 = quantile(X1, .75),\n              q2_75 = quantile(X2, .75),\n              q3_75 = quantile(X3, .75),\n              \n              ## IQR: exclude them because they create a high correlations with quantiles (already delivers the same information)\n              #iqr1 = iqr_fun(X1),\n              #iqr2 = iqr_fun(X2),\n              #iqr3 = iqr_fun(X3),\n\n              ## skewness:\n              skew1 = e1071::skewness(X1),\n              skew2 = e1071::skewness(X2),\n              skew3 = e1071::skewness(X3),\n\n              ## Median absolute deviation:\n              mad1 = mad(X1),\n              mad2 = mad(X2),\n              mad3 = mad(X3),\n              \n              ## mode:\n              mode1 = mode_fun(X1),\n              mode2 = mode_fun(X2),\n              mode3 = mode_fun(X3),\n\n              ## Maximum and Minimum:\n              max1 = max(X1),\n              max2 = max(X2),\n              max3 = max(X3),\n              min1 = min(X1),\n              min2 = min(X2),\n              min3 = min(X3),\n              \n              ## kurtosis\n              kur1 = e1071::kurtosis(X1),\n              kur2 = e1071::kurtosis(X2),\n              kur3 = e1071::kurtosis(X3),\n              \n              # Standard Error:\n              se1 = se_fun(X1),\n              se2 = se_fun(X2),\n              se3 = se_fun(X3),\n              \n              # Root mean square: \n              rms1 = rms_fun(X1),\n              rms2 = rms_fun(X2),\n              rms3 = rms_fun(X3),\n              \n              ## Coefficient of variance\n              coefvar1 = sd1/m1,\n              coefvar2 = sd2/m2,\n              coefvar3 = sd3/m3,\n              \n              ## mean frequency:\n              mfreq1 = mean_freq(X1),\n              mfreq2 = mean_freq(X2),\n              mfreq3 = mean_freq(X3),\n              \n              ## spectral peak:\n              peak1 = spec_peak(X1),\n              peak2 = spec_peak(X2),\n              peak3 = spec_peak(X3),\n\n              ## spectral mean frequency:\n              s_meanfreq1 = spec_mean_freq(X1),\n              s_meanfreq2 = spec_mean_freq(X2),\n              s_meanfreq3 = spec_mean_freq(X3),\n\n              ## spectral standard deviation:\n              s_sd1 = spec_sd(X1),\n              s_sd2 = spec_sd(X2),\n              s_sd3 = spec_sd(X3),\n              \n              ## spectral entropy:\n              s_ent1 = spec_ent(X1),\n              s_ent2 = spec_ent(X2),\n              s_ent3 = spec_ent(X3),\n\n            # Others\n              ## pattern detection:\n              conv1 = conv_fun(X1, length(unique(epoch))), #defining length of unique(epoch) as m (limited number of samples)\n              conv2 = conv_fun(X2, length(unique(epoch))),\n              conv3 = conv_fun(X3, length(unique(epoch))),\n\n              ## Zero-Crossings:\n              crossing1 = 0.5 * mean(abs(sign(X1 * (sampleid + 1)) - sign(X1 * sampleid))), #here t is defined as sampleid\n              crossing2 = 0.5 * mean(abs(sign(X2 * (sampleid + 1)) - sign(X2 * sampleid))), \n              crossing3 = 0.5 * mean(abs(sign(X3 * (sampleid + 1)) - sign(X3 * sampleid))), \n\n              ## SMA:\n              SMA = sma_fun(X1, X2, X3),\n\n              ## Width height of histogram ratio:\n              whratio1 = X1[which.max(X1)]/length(sampleid),\n              whratio2 = X2[which.max(X2)]/length(sampleid),\n              whratio3 = X3[which.max(X3)]/length(sampleid),\n\n              # Difference between highest peak and lowest valley:\n              diff_pv1 = max(X1) - min(X1),\n              diff_pv2 = max(X2) - min(X2),\n              diff_pv3 = max(X3) - min(X3)\n          ) \n    \n    usertimedom\n}\n","metadata":{"_uuid":"daccc2b4175580864f72a2012ef6d56ee7c0a883","execution":{"iopub.status.busy":"2022-09-28T15:18:04.407773Z","iopub.execute_input":"2022-09-28T15:18:04.410237Z","iopub.status.idle":"2022-09-28T15:18:04.431633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# run this to see if all functions are working well/ see raw data outputs\nfilename = \"./RawData/Train/acc_exp01_user01.txt\"\ndf = extractTimeDomainFeatures(filename, sample_labels) \nhead(df) #to visaulize the dataframe","metadata":{"_uuid":"d27ff61c2208bdd5366eac15153ad1086de930db","execution":{"iopub.status.busy":"2022-09-28T15:18:06.564464Z","iopub.execute_input":"2022-09-28T15:18:06.566616Z","iopub.status.idle":"2022-09-28T15:18:08.475963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we'll combine both acc and gyro files into one big file:","metadata":{}},{"cell_type":"code","source":"#accelorometer file \nacc_filenames <- dir(\"./RawData/Train/\", \"^acc\", full.names = TRUE)\n#gyroscope file\ngyro_filenames <- dir(\"./RawData/Train/\", \"^gyro\", full.names = TRUE) \n\n# map_dfr runs `extractTimeDomainFeatures` on all elements in \n# filenames and binds results row wise\nacc_myData = map_dfr(acc_filenames, extractTimeDomainFeatures, sample_labels) #files with acc\ngyro_myData = map_dfr(gyro_filenames, extractTimeDomainFeatures, sample_labels) #files with gyro\n\n# Check the result\n#head(myData1)\n#head(myData2)\n\n#merge them into one big file\ntrain_myData <- acc_myData %>%\n    left_join(gyro_myData, \n              by = c('epoch', 'user_id', 'exp_id', 'sampleid', 'n_samples', 'activity'),\n              \n              #changing the name of features with _acc or _gyro depends on file\n              suffix = c(\"_acc\", \"_gyro\")) %>% # to distinguish the variables by both sensors\n    select(-activity, activity) #activity as last label (from Group 8)\nhead(train_myData)","metadata":{"_uuid":"c2572d092b5b590a3f6dcc67313ff5f690beb471","execution":{"iopub.status.busy":"2022-09-28T15:18:29.338296Z","iopub.execute_input":"2022-09-28T15:18:29.340537Z","iopub.status.idle":"2022-09-28T15:20:48.990658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.1 Data Pre-Processing\n\nUsing obervation and caret package to remove redundant variables\n* Variables that only gives output of 0 or NAs\n* Variables with near zero variation\n    - Have all same values or all NAs\n    - Compare most frequent to second most frequent value\n    - Compare number of unique values to number of observations\n* Variables that are highly correlated\n    - High correlation between variables provide similar or same information\n    - May be an indicator of instability of coefficient estimates","metadata":{}},{"cell_type":"code","source":"# Remove all the NAs from the the dataset \n# credit to Group 8\n\nmyData_final <- train_myData %>%\n    drop_na() %>%\n    dplyr::select(-c(epoch:n_samples))","metadata":{"execution":{"iopub.status.busy":"2022-09-28T15:21:04.102384Z","iopub.execute_input":"2022-09-28T15:21:04.104343Z","iopub.status.idle":"2022-09-28T15:21:04.17494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check for near zero variation\nnonearva <- caret::nearZeroVar(myData_final %>%\n    dplyr::select(-activity))\n\n# check for high correlations\nvar <- cor(myData_final %>%\n    dplyr::select(-activity)) %>% \n    caret::findCorrelation(0.9)\n\n# cleaning the data\nmyData_clean <- myData_final %>% \n    dplyr::select(-all_of(c(nonearva, var)))","metadata":{"execution":{"iopub.status.busy":"2022-09-28T15:21:06.686189Z","iopub.execute_input":"2022-09-28T15:21:06.688117Z","iopub.status.idle":"2022-09-28T15:21:10.541704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Next step, we will be using car package to remove multicollinear variables:\n* Aims to remove the variables in a regression that are correlated with each other\n* Variance inflation factor (VIF) is the ratio of the variance of variables when fitting the full model divided by the variance of variables if fit on its own (ISLR Chapter 3-4).","metadata":{}},{"cell_type":"code","source":"# Credits to Group 8\n\nVIF <- function(data) {\n    vif_over <- c() # creating list to store affected column names\n    for (i in 1:(length(data)-1)){\n      lmp <- paste(colnames(data[, i, drop = F]), \n                   \"~\", \n                   paste(colnames(data[,-c(i,(length(data)-1))]), collapse = \"+\"))\n      # above line creates a formula string for each predictor regressed on all others\n      fit <- lm(data = data, formula = lmp) # fitting the model using the formula string\n      VIF <- 1/(1 - summary(fit)$r.squared) # calulcating the VIF\n      #print(paste(colnames(data[, i, drop = F]), VIF, sep = \": \"))\n\n      if (VIF > 10){\n          vif_over <- append(vif_over, colnames(data[,i])) # storing features with VIFs>10\n      }\n    }\n    return(vif_over)\n}\n\n\n# Removing the observations that show high multicollinearity (VIF > 10)\nmyData_cleanM <- myData_clean %>% \n    dplyr::select(-all_of(VIF(myData_clean)))\n\nhead(myData_cleanM) #visualize the final clean data frame","metadata":{"execution":{"iopub.status.busy":"2022-09-28T15:21:19.02652Z","iopub.execute_input":"2022-09-28T15:21:19.028487Z","iopub.status.idle":"2022-09-28T15:21:33.673945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Model fitting\n## 4.1 Linear Discriminant Analysis\nLinear discriminant analysis (LDA) is one of the classification methods that is bascially a linear regression analysis with a dichotomous outcome (0 or 1). The characteristics of LDA is that it can 1) formulate for any distribution, 2) models distribution of the predictor variables within each class k, and uses Bayes theorem to compute the posterior probability that an observation belongs to class k, 3) assumes a normal distribution for X. If the normal distribution is correct, LDA's decision boundaries are the Bayes decision boundaries that yield the lowest number of misclassifications among all classification models. Thus, we are using LDA to fit our predictors. (ISLR Chapter 4)\n\nFor validating the model, we used k = 10 because typically, k = 5 or 10 are ideal values to yield test error rate estimates that suffer neither from excessively high bias nor from very high variance, so we chose k = 10 as our cross validation.\n\nFINE TUNING AND STEPWISE REGRESSION FOR LDA\n* During the process of finding ways to tune LDA, we found out that according to the documentation LDA has no tuning parameters.\n    - http://topepo.github.io/caret/available-models.html\n* We tried using stepLDA to fit stepwise regression for LDA, but due to high computational power it did not successfully run, so we decided to leave it out.\n","metadata":{"_uuid":"689e96162446707ee9e88a4c229d169f76290b62"}},{"cell_type":"code","source":"## Fitting classifier models\n# 10-fold\ntrcntr = caret::trainControl('cv', number = 10) \n\n#fitting Linear Discriminant Analysis\nfit_lda = caret::train(activity ~ ., data = myData_cleanM, method=\"lda\", trControl = trcntr, na.action = na.pass)\nfit_lda","metadata":{"execution":{"iopub.status.busy":"2022-09-28T15:29:07.373532Z","iopub.execute_input":"2022-09-28T15:29:07.376229Z","iopub.status.idle":"2022-09-28T15:29:10.899272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.2 K-Nearest Neighbors\n\nK-nearest neighbors (KNN) is a non-parametric approach, meaning it does not assume anything of the decision boundary. One of the advantages of non-parametric model is that it can display better output when the decision boundary is non-linear. Since we have a lot of observations, we would expect less bias outcome. The flexibility of KNN would thus be appropriate for our model. \n\nTUNING\n* According to the documentation knn has one tuning parameter: k\n* For the ideal amount of k sould be the squarroot of the amount of samples we have. Since we have 20597 samples the squareroot will be 143.5 so we will look for a k around that number.\n    - According to https://towardsdatascience.com/how-to-find-the-optimal-value-of-k-in-knn-35d936e554eb#:~:text=The%20optimal%20K%20value%20usually,be%20aware%20of%20the%20outliers.","metadata":{}},{"cell_type":"code","source":"set.seed(1) #to avoid randomness\nsqrt(max(user_df$sampleid)) #to see the optimal k value for tuning process\n\n#fitting k-Nearest Neighbors\n#size matters for knn so standardizing features are important\n#with fine-tunning\nhyperparams <- expand.grid(k = seq(140,150,1))\nfit_knn <- caret::train(activity ~ ., data = myData_cleanM, method=\"knn\", trControl = trcntr, tuneGrid = hyperparams, preProcess = 'scale')\nfit_knn # the output shows the final value of k\n\n#without fine-tunning\nfit_knn_wo <- caret::train(activity ~ ., data = myData_cleanM, method=\"knn\", trControl = trcntr, preProcess = 'scale')\nfit_knn_wo\n\n#for visualization of ideal k, credit to Group 7\nplot(fit_knn)\nplot(fit_knn_wo)","metadata":{"execution":{"iopub.status.busy":"2022-09-28T15:36:27.165024Z","iopub.execute_input":"2022-09-28T15:36:27.167638Z","iopub.status.idle":"2022-09-28T15:37:40.991879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.3 Multinomial Logistic Regression\nWhen there are more than two classes, multinomial logitistic regression can be an appropriate model (as an extension from normal logistic regression model). However, our group decided to not use the model because the fitted MLR model required a high computational power and yield a low accuracy compared to that of others. Considering these factors, we thought it is not necessary to display the codes. These are the outputs we got:\n\n![mlr screenshot.png](attachment:7b98bffc-da44-4589-9a0e-1369bccd3b48.png)","metadata":{},"attachments":{"7b98bffc-da44-4589-9a0e-1369bccd3b48.png":{"image/png":"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"}}},{"cell_type":"markdown","source":"## 4.4 Cross-Validation\n\nCross-validation is a common resampling methods: it can be used ot estimate the test error to evaluate the performance, and select the appropriate level of flexibility. This is also known as *model assessment*. We used k-fold cross validation for our knn model because it does not take much computational power as compared to LOOCV. Also, we can determine how well a given statistical learning procedure can be expected to perform on independent data. (ISLR Chapter 5)\n\n* LOOCV for LDA was not used due to high computational power.\n\n","metadata":{}},{"cell_type":"code","source":"# CV for KNN\n# 10-fold CV\n# set the 'train control'\n\ntrControlKNN <- trainControl(method = \"cv\", number = 10)\nfit_cv_knn <- caret::train(activity ~ ., method = \"knn\", \n                         tuneGrid = expand.grid(k= 1:10), \n                         trControl = trControlKNN, \n                         metric = \"Accuracy\", \n                         data = myData_cleanM,\n                         preProcess = 'scale') #standardizing features\nfit_cv_knn","metadata":{"execution":{"iopub.status.busy":"2022-09-28T15:45:21.815147Z","iopub.execute_input":"2022-09-28T15:45:21.817213Z","iopub.status.idle":"2022-09-28T15:46:06.041088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.5 Model Comparison\n\nBelow, we visualized accuracy of different models with two different graphs:\n* Bar plot: simply visualizes the best accuracy among all the models we have fitted\n* Scatterplot with confidence interval: visualizes the accuracy rate as well as the range of confidence interval","metadata":{}},{"cell_type":"code","source":"#bar graph that visualizes the best accuracy among different models\n# credit to Raoul\nall_models <- list(lda = fit_lda, knn = fit_knn, knnwo = fit_knn_wo, cv_knn = fit_cv_knn) #update when more models are added\n#extract the cross-validated accuracies from each model\nAcc = sapply(all_models, function(md1) {max(md1$results$Accuracy)})\n# make a barplot with only the best perfroming model in red\ncolor = 1 + (Acc >= max(Acc))\nb <- barplot(Acc, horiz = T, las=1, col = color) \n             \n# Accuracy with confidence interval graph\n# Credit to group 4\nggplot(resamples(all_models)) +\n    labs(y = \"Accuracy\") + \n    theme_linedraw() +\n    scale_y_reverse()","metadata":{"execution":{"iopub.status.busy":"2022-09-28T15:46:44.418227Z","iopub.execute_input":"2022-09-28T15:46:44.419826Z","iopub.status.idle":"2022-09-28T15:46:44.984924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Confusion Matrix for the final model\n\nConfusion matrix is displayed below to compare the predictions to the true default statuses for the training observations. It shows the frequencies of each class being correctly or incorrectly classified to each other. More details can be found in conclusion section.","metadata":{}},{"cell_type":"code","source":"# Confusion matrix CV- KNN\n# Make train and test dataset\ntrain_split_idx <- caret::createDataPartition(myData_cleanM$activity, p = 0.75, list = FALSE)\ntrain <- myData_cleanM[train_split_idx, ]\ntest <- myData_cleanM[train_split_idx, ]\n\ntrain[[\"activity\"]] = factor(train[[\"activity\"]])\ntest[[\"activity\"]] = factor(test[[\"activity\"]])\n\n# Prediction\nfit_cvknn_predict <- predict(fit_cv_knn, newdata = test)\n\n# confusion matrix\ncm_cvknn <- confusionMatrix(test$activity, fit_cvknn_predict)\n\ncm_cvknn[2:4] #print out table, overall accuracy, and specificity & sensitivity for each class\n\n# other ways to display the outputs\n# table cm\n# cm_cvknn_table <- cm_cvknn$table\n# make table of statistics\n# cm_cvknn_st <- data.frame(cm_cvknn$overall)\n","metadata":{"execution":{"iopub.status.busy":"2022-09-28T15:48:27.250651Z","iopub.execute_input":"2022-09-28T15:48:27.252488Z","iopub.status.idle":"2022-09-28T15:48:30.500295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion:\n\nThe aim of our project was to detect and recognize physical activities of human, recorded by smartphones. We added several features, including features we came up with ourselves based on literature research. Unfortunately, we were not able to use all the features we came up with. For instance, while reading different literatures, we found out that package quantmod provides some fruitful information about the signals. Thus we tried to extract the mathematical formulas out of the package, but due to the difficulty of recreating the package and time pressure, we ended up not using the features. We fitted several models to our data to predict the activities. All accuracies are visualized in the plot under the heading âmodel comparisonâ. As can be clearly seen there, the cross-validated knn model gave the best accuracy, as well as smallest range of confidence intervals. However, due to the curse of dimensionality, knn is more prone to overfitting. Although feature selection and dimensionality reduction techniques can be used to avoid this, the results should still be interpreted with caution. In the future, other features, such as the peak and valley feature could be added to investigate whether this improves accuracy. For instance, it seems to be hard to distinguish between 'Lie to sit' and 'Lie to stand' based on the confusion matrix: while 'Lie to stand' was correctly classified with 'Lie to stand' 19 times, 'Lie to sit' to 'Lie to stand' was incorrectly classified for 11 times. This indicates that those two categories are quite similar, which could possibly be improved with peaks and valleys features.","metadata":{}},{"cell_type":"markdown","source":"## Sub-Section: Peaks and Valleys:\nWhen looking at the plot below (same as earlier) we see that different activities have different values for the signals. We also see in this plot that there is a clear difference between the vallues that are associated with walking downstair and laying for example. one difference we see is that the average of the signal for walking downstairs is higher then for laying. We also see that the amount of higher/lower values for walking down stairs seems to be higher then those for laying. So here we can definately see some reasons to think that peaks and valleys of a time period could help distinguis the different activities from eachother.","metadata":{}},{"cell_type":"code","source":"options(repr.plot.width=15) # change plot width for nicer output\n\nuser_df %>% \n  ggplot(aes(x = sampleid, y = X1, col = factor(activity), group=segment)) + \n      geom_line()  ","metadata":{"execution":{"iopub.status.busy":"2022-09-28T15:48:46.15241Z","iopub.execute_input":"2022-09-28T15:48:46.154457Z","iopub.status.idle":"2022-09-28T15:48:47.130108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To do this we first used a package (quantmod) which has an algorithm that compairs a time x with its time x-1 and a time x+1. This algorithm then defines a peak when both X-1 and X+2 are smaller than X. It defines a valley the other way around. In the graph below we can see this package working on the data. \n\ndocumentation for the peaks and valleys functions can be found:\n - https://search.r-project.org/CRAN/refmans/quantmod/html/peak.html for peaks\n - https://www.rdocumentation.org/packages/geodiv/versions/1.0.1/topics/findvalleys for valleys","metadata":{}},{"cell_type":"code","source":"#here we find which points are the peaks of a sequence in time\np <- quantmod::findPeaks(user_df$X1[1:128]) -1\n\n#here we find the points which are the valleys of the sequence of time\nv <- quantmod::findValleys(user_df$X1[1:128]) -1\n\n#visualization\nplot(user_df$X1[1:128],type = 'l')\npoints(p,user_df$X1[p], col = \"red\")\npoints(v,user_df$X1[v],col = \"blue\")","metadata":{"execution":{"iopub.status.busy":"2022-09-28T15:48:58.257426Z","iopub.execute_input":"2022-09-28T15:48:58.259361Z","iopub.status.idle":"2022-09-28T15:48:58.430353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"However, in this competition using this package was prohibited, so we had to think up another way. Making a function that compairs the three values is the easy part (this part is shown below). However it should work in the current give format which was way harder to work with. Thus, it was decided to not venture further into this rabit hole.\nBelow is to demonstrate the work we did:","metadata":{}},{"cell_type":"code","source":"max <- 128\nperiod <- user_df$X1[1:max]\npeak = c()\nif(period[1] < period[2]) peak[1] = 0 else peak[1] = 1\n    \nfor(time in 2:(max-1)){\n    if(period[time] > period[time -1] & period[time] > period [time+1]) peak[time] = 1 else peak[time] = 0\n        }\nif(period[max] > period[max-1]) peak[max] = 1 else peak[max] = 0\n\nvalley = c()\nif(period[2] < period[1]) valley[1] = 0 else valley[1] = 1\n\nfor(time in 2:(max-1)){\n    if (period[time] < period[time -1] & period[time] < period[time +1]) valley[time] = 1 else valley[time] = 0\n}\nif(period[max] < period[max-1]) valley[max] = 1 else valley[max] = 0\n\nvalley <- which(valley == 1)\npeak <- which(peak == 1)\n\nplot(user_df$X1[1:max], type = 'l') +\npoints(peak,user_df$X1[peak], col = \"red\") +\npoints(valley,user_df$X1[valley], col = \"blue\")","metadata":{"execution":{"iopub.status.busy":"2022-09-28T15:49:00.746134Z","iopub.execute_input":"2022-09-28T15:49:00.747926Z","iopub.status.idle":"2022-09-28T15:49:00.952251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Submissions\n\n\nThe test data can be imported in the same way as the training data, you only have to change `Train` to `Test` in the directory path:","metadata":{"_uuid":"63f77917e08cd690655137184750cfac494607ce"}},{"cell_type":"code","source":"#acc file \nacc_filenames_test <- dir(\"./RawData/Test/\", \"^acc\", full.names = TRUE)\n#gyro file\ngyro_filenames_test <- dir(\"./RawData/Test/\", \"^gyro\", full.names = TRUE) \n\n# map_dfr runs `extractTimeDomainFeatures` on all elements in \n# filenames and binds results row wise\nmyData1_test = map_dfr(acc_filenames_test, extractTimeDomainFeatures, sample_labels) #files with acc\nmyData2_test = map_dfr(gyro_filenames_test, extractTimeDomainFeatures, sample_labels) #files with gyro\n\n#merge them into one big file\nmyData_test <- myData1_test %>%\n    left_join(myData2_test, #joining the data; do I use full_join or inner_join..?\n                       by = c('epoch', 'user_id', 'exp_id', 'activity', 'sampleid', 'n_samples'),\n                   suffix = c(\"_acc\", \"_gyro\")) \nhead(myData_test)","metadata":{"execution":{"iopub.status.busy":"2022-09-28T15:49:05.845721Z","iopub.execute_input":"2022-09-28T15:49:05.848463Z","iopub.status.idle":"2022-09-28T15:50:03.12377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filenames_test = list.files(\"./RawData/Test/\", \"^acc\", full.names = TRUE)\nfilenames_test","metadata":{"_uuid":"a3685833978c44b58b05ac67caffa3c796a9f73a","execution":{"iopub.status.busy":"2022-09-28T15:50:12.999227Z","iopub.execute_input":"2022-09-28T15:50:13.001195Z","iopub.status.idle":"2022-09-28T15:50:13.026168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Formatting the submission file\n\nTo help you turning your predictions into the right format, the following code can help. Here it is executed on the training set data frame, but the same can be applied to the test set data frame.","metadata":{"_uuid":"9d6811f2aa519b89fdd455e046c1201e82109a67","trusted":true}},{"cell_type":"code","source":"#prediction\npre_test = predict(fit_cv_knn, new = myData_test)\n\npredictions = myData_test %>%\n    mutate(activity = pre_test)\n\ndim(predictions)","metadata":{"execution":{"iopub.status.busy":"2022-09-28T16:31:08.115016Z","iopub.execute_input":"2022-09-28T16:31:08.117186Z","iopub.status.idle":"2022-09-28T16:31:09.983327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions %>%\n    # prepend \"user\" and \"exp\" to user_id and exp_id\n    mutate(\n        user_id = paste(ifelse(user_id < 10, \"user0\", \"user\"), user_id, sep=\"\"), \n        exp_id = paste(ifelse(exp_id < 10, \"exp0\", \"exp\"), exp_id, sep=\"\")\n    ) %>% \n\n    # unit columnes user_id, exp_id and sample_id into a string \n    # separated by \"_\" and store it in the new variable `Id`\n    unite(Id, user_id, exp_id, sampleid) %>%\n\n    # retain only the `Id` and  predictions\n    select(Id, Predicted = activity) %>%\n\n    # write to file\n    write_csv(\"submission.csv\")\n\n\n# Check the result: print first 20 lines in the submission file\ncat(readLines(\"submission.csv\",20), sep=\"\\n\")\n","metadata":{"execution":{"iopub.status.busy":"2022-09-28T16:31:11.811886Z","iopub.execute_input":"2022-09-28T16:31:11.814212Z","iopub.status.idle":"2022-09-28T16:31:11.903864Z"},"trusted":true},"execution_count":null,"outputs":[]}]}